{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exm01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5eotWNMyDhlKqgHjc+18n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alifzl/Zhaav-MINER-Scripts/blob/main/exm01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3c06IFl-xfK"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "from typing import Union\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.pandas import *\n",
        "from pyspark.ml.classification import *\n",
        "from pyspark.ml.evaluation import *\n",
        "from pyspark.sql import functions\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create sparksesion in order to use spark sql:"
      ],
      "metadata": {
        "id": "QPS8w2aPEKF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createSparkSession(appname:str):\n",
        "        '''\n",
        "        create spark session rdd.\n",
        "            Parameters:\n",
        "            ---------- \n",
        "                    appname (str): The appliction name  \n",
        "                    \n",
        "\n",
        "            Returns:\n",
        "                    SparkSession\n",
        "\n",
        "        '''\n",
        "        \n",
        "        import pyspark\n",
        "        from pyspark.sql import SparkSession\n",
        "        spark = SparkSession.builder.appName(appname).getOrCreate()\n",
        "        return spark"
      ],
      "metadata": {
        "id": "EKR3oFy-Bdcc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=createSparkSession(\"exp01\")"
      ],
      "metadata": {
        "id": "Gwxf7KZRx2BQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read CSV file into DataFrame with schema and header\n"
      ],
      "metadata": {
        "id": "rB0MbE_dD3L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readcsvfile(header:str,inferSchema:str,appname:str,path:str,sep:str):\n",
        "        '''\n",
        "        create dataframe by reading csv file.\n",
        "            Parameters:\n",
        "            ---------- \n",
        "                    header(str):  auto detect header of the file  ,\n",
        "                  \n",
        "                    inferSchema(str):  auto detect type of columns,\n",
        "                    \n",
        "                    appname(str):  The appliction name,\n",
        "                    \n",
        "                    path(str):    file path\n",
        "                    \n",
        "                    sep(str): columns separator\n",
        "\n",
        "            Returns\n",
        "        --------------\n",
        "               dataframe( :class:`DataFrame) : return dataframe out of csv file\n",
        "\n",
        "        '''\n",
        "        spark=createSparkSession(appname)\n",
        "        dataframe=spark.read.csv(path,header=header,inferSchema=inferSchema,sep=sep) \n",
        "        return dataframe"
      ],
      "metadata": {
        "id": "wayYYq7DDgOr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=readcsvfile(header=True,inferSchema=True,appname=\"exp01\",path='/content/diabetes.csv',sep=',')"
      ],
      "metadata": {
        "id": "tm89VvgcEXI7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(dataframe,number:int=None,truncate:bool=None):\n",
        "        '''\n",
        "        show the dataframe .\n",
        "        \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "                    \n",
        "            number(int) : optional, number of rows to show.\n",
        "            \n",
        "            truncate : bool, optional\n",
        "            If set to ``True``, truncate strings longer than 20 chars by default.\n",
        "            If set to a number greater than one, truncates long strings to length ``truncate``\n",
        "            and align cells right.\n",
        "            \n",
        "            Returns\n",
        "        --------------\n",
        "               \"\"\"Prints the first ``n`` rows to the console.\n",
        "\n",
        "    \n",
        "\n",
        "        \n",
        "\n",
        "                '''\n",
        "        dataframe.show(number,truncate)"
      ],
      "metadata": {
        "id": "syTfz-VJE0Z3"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## common command"
      ],
      "metadata": {
        "id": "XO8QyuyCGjja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### show the dataframe"
      ],
      "metadata": {
        "id": "oiNO-rQdGW2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show(df,5,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNNbHIAeFPEJ",
        "outputId": "7dda480c-be09-48d6-eb4f-28671be3eade"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|6          |148    |72           |35           |0      |33.6|0.627                   |50 |1      |\n",
            "|1          |85     |66           |29           |0      |26.6|0.351                   |31 |0      |\n",
            "|8          |183    |64           |0            |0      |23.3|0.672                   |32 |1      |\n",
            "|1          |89     |66           |23           |94     |28.1|0.167                   |21 |0      |\n",
            "|0          |137    |40           |35           |168    |43.1|2.288                   |33 |1      |\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### type of dataframe column"
      ],
      "metadata": {
        "id": "sLaI8HvfGqhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframetype(dataframe):\n",
        "    \"\"\"Returns all column names and their data types as a list\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "                    \n",
        "        Returns\n",
        "        --------------\n",
        "               Prints types of the rows \"\"\"\n",
        "    return dataframe.dtypes"
      ],
      "metadata": {
        "id": "2CF-VImKFUFE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframetype(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox6RTCPyFfY_",
        "outputId": "28315ca1-8106-4f6f-c2d0-baa7eed2bf9a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pregnancies', 'int'),\n",
              " ('Glucose', 'int'),\n",
              " ('BloodPressure', 'int'),\n",
              " ('SkinThickness', 'int'),\n",
              " ('Insulin', 'int'),\n",
              " ('BMI', 'double'),\n",
              " ('DiabetesPedigreeFunction', 'double'),\n",
              " ('Age', 'int'),\n",
              " ('Outcome', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### statistic describe dataframe"
      ],
      "metadata": {
        "id": "iOx7YAL-Ok0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def statisticdescribe(dataframe):\n",
        "        \"\"\"Returns statistics summary of dataframe\n",
        "        \n",
        "        Parameters:\n",
        "        --------------\n",
        "        dataframe(:class:`DataFrame) : select dataframe\n",
        "\n",
        "        Returns\n",
        "        --------------\n",
        "              :class:`DataFrame\"\"\"\n",
        "        dataframe_new=dataframe.describe()\n",
        "        return dataframe_new"
      ],
      "metadata": {
        "id": "4IxYlhtpFhAe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statisticdescribe(df).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmaF5dXGG9vG",
        "outputId": "c268e35b-5d63-46f6-f0f8-6d2aab769526"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
            "|summary|       Pregnancies|          Glucose|     BloodPressure|     SkinThickness|           Insulin|               BMI|DiabetesPedigreeFunction|               Age|           Outcome|\n",
            "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
            "|  count|               768|              768|               768|               768|               768|               768|                     768|               768|               768|\n",
            "|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.992578124999977|      0.4718763020833327|33.240885416666664|0.3489583333333333|\n",
            "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803| 7.884160320375441|       0.331328595012775|11.760231540678689| 0.476951377242799|\n",
            "|    min|                 0|                0|                 0|                 0|                 0|               0.0|                   0.078|                21|                 0|\n",
            "|    max|                17|              199|               122|                99|               846|              67.1|                    2.42|                81|                 1|\n",
            "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### list of the columns"
      ],
      "metadata": {
        "id": "y0JizKcqOvNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coloumes(dataframe):\n",
        "    \"\"\"Returns all column names  as a list\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "                    \n",
        "        Returns\n",
        "        --------------\n",
        "               Prints all column names \"\"\"\n",
        "    return dataframe.columns"
      ],
      "metadata": {
        "id": "6fBp0g-IHCIi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coloumes(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUw0I8BrLi7Z",
        "outputId": "39833dbf-fb08-4ef2-b014-43d27e9b4b35"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pregnancies',\n",
              " 'Glucose',\n",
              " 'BloodPressure',\n",
              " 'SkinThickness',\n",
              " 'Insulin',\n",
              " 'BMI',\n",
              " 'DiabetesPedigreeFunction',\n",
              " 'Age',\n",
              " 'Outcome']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### select and show some columns"
      ],
      "metadata": {
        "id": "i-Mu-PmzOcNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select(dataframe,coloumes:Union[list, str]):\n",
        "    \"\"\"select specfic columns by name and return new dataframe\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "            \n",
        "            coloumes(str/list): list of string coloumes names         \n",
        "\n",
        "        Returns\n",
        "        --------------\n",
        "              dataframe_new(:class:`DataFrame ): return new dataframe\n",
        "              \n",
        "              \n",
        "        Example\n",
        "        -------------- \n",
        "            1- common select \n",
        "                \n",
        "                dataframe_new=dataframe.select(\"name\")\n",
        "\n",
        "\n",
        "            \n",
        "            \n",
        "            2- also can slicing the dataframe with start and end\n",
        "            \n",
        "                dataframe_new=dataframe.select(dataframe.columns[start=10:end=20])\"\"\"\n",
        "    dataframe_new=dataframe.select(coloumes)\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "D1eMXTJ2MF-3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select(df,[\"Pregnancies\",\"Glucose\",\"BloodPressure\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdW7yxGSMmfj",
        "outputId": "5a236463-3556-45fe-fe32-80ab7a8b6326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+\n",
            "|Pregnancies|Glucose|BloodPressure|\n",
            "+-----------+-------+-------------+\n",
            "|          6|    148|           72|\n",
            "|          1|     85|           66|\n",
            "|          8|    183|           64|\n",
            "|          1|     89|           66|\n",
            "|          0|    137|           40|\n",
            "|          5|    116|           74|\n",
            "|          3|     78|           50|\n",
            "|         10|    115|            0|\n",
            "|          2|    197|           70|\n",
            "|          8|    125|           96|\n",
            "|          4|    110|           92|\n",
            "|         10|    168|           74|\n",
            "|         10|    139|           80|\n",
            "|          1|    189|           60|\n",
            "|          5|    166|           72|\n",
            "|          7|    100|            0|\n",
            "|          0|    118|           84|\n",
            "|          7|    107|           74|\n",
            "|          1|    103|           30|\n",
            "|          1|    115|           70|\n",
            "+-----------+-------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### list of all rows"
      ],
      "metadata": {
        "id": "lSfvqZCBOWw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect(dataframe)->list:\n",
        "  \"\"\" return all of dataframe as list\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "            \n",
        "                   \n",
        "\n",
        "        Returns\n",
        "        --------------\n",
        "              ListData(list): list of all dataframe \"\"\"\n",
        "\n",
        "  ListData=dataframe.collect()\n",
        "  return ListData"
      ],
      "metadata": {
        "id": "r7T1hufdNwXN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collect(df)[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAuImqi1N1QQ",
        "outputId": "b27e7cad-d27d-4995-a43c-f92bd27902d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1),\n",
              " Row(Pregnancies=1, Glucose=85, BloodPressure=66, SkinThickness=29, Insulin=0, BMI=26.6, DiabetesPedigreeFunction=0.351, Age=31, Outcome=0),\n",
              " Row(Pregnancies=8, Glucose=183, BloodPressure=64, SkinThickness=0, Insulin=0, BMI=23.3, DiabetesPedigreeFunction=0.672, Age=32, Outcome=1),\n",
              " Row(Pregnancies=1, Glucose=89, BloodPressure=66, SkinThickness=23, Insulin=94, BMI=28.1, DiabetesPedigreeFunction=0.167, Age=21, Outcome=0),\n",
              " Row(Pregnancies=0, Glucose=137, BloodPressure=40, SkinThickness=35, Insulin=168, BMI=43.1, DiabetesPedigreeFunction=2.288, Age=33, Outcome=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common filtering"
      ],
      "metadata": {
        "id": "tsHBXzlGOKSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### starts with"
      ],
      "metadata": {
        "id": "fGkklVYNPGaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def startswith(dataframe,columns:str,value:str):\n",
        "    \"\"\" return all row of dataframe as a new dataframe that starts with the value  \n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "\n",
        "            columns(str) : columns of dataframe\n",
        "            \n",
        "                   \n",
        "\n",
        "        Returns\n",
        "        --------------\n",
        "              dataframe_new(:class:`DataFrame): dataframe of the value\"\"\"\n",
        "    dataframe_new=dataframe.where(dataframe[columns].startswith(value))\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "aQ2x7Rd9N-Uw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startswith(df,\"Glucose\",\"89\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEPiLR2NO5hc",
        "outputId": "6bda9c64-fafa-420b-abb1-f1519576bd03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          1|     89|           76|           34|     37|31.2|                   0.192| 23|      0|\n",
            "|          3|     89|           74|           16|     85|30.4|                   0.551| 38|      0|\n",
            "|          2|     89|           90|           30|      0|33.5|                   0.292| 42|      0|\n",
            "|          1|     89|           24|           19|     25|27.8|                   0.559| 21|      0|\n",
            "|          9|     89|           62|            0|      0|22.5|                   0.142| 33|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### endswith"
      ],
      "metadata": {
        "id": "L8sNl2YCPI4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def endswith(dataframe,columns:str,value:str):\n",
        "    \"\"\" return all row of dataframe as a new dataframe that ends with the value \n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "\n",
        "            columns(str) : columns of dataframe\n",
        "            \n",
        "                   \n",
        "\n",
        "        Returns\n",
        "        --------------\n",
        "              dataframe_new(:class:`DataFrame): dataframe of the value\"\"\"\n",
        "    dataframe_new=dataframe.where(dataframe[columns].endswith(value))\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "RClydx9bPCm-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endswith(df,\"DiabetesPedigreeFunction\",\"2\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbKCOw_HPKiG",
        "outputId": "df5f6fab-78ce-455e-843a-948dfc6b7ca1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
            "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
            "|         10|    122|           78|           31|      0|27.6|                   0.512| 45|      0|\n",
            "|         11|    138|           76|            0|      0|33.2|                    0.42| 35|      0|\n",
            "|          5|     88|           66|           21|     23|24.4|                   0.342| 30|      0|\n",
            "|          0|    100|           88|           60|    110|46.8|                   0.962| 31|      0|\n",
            "|          2|     74|            0|            0|      0| 0.0|                   0.102| 22|      0|\n",
            "|          1|    163|           72|            0|      0|39.0|                   1.222| 33|      1|\n",
            "|          0|    125|           96|            0|      0|22.5|                   0.262| 21|      0|\n",
            "|          1|     89|           76|           34|     37|31.2|                   0.192| 23|      0|\n",
            "|          5|    124|           74|            0|      0|34.0|                    0.22| 38|      1|\n",
            "|          3|    120|           70|           30|    135|42.9|                   0.452| 30|      0|\n",
            "|          0|     93|           60|           25|     92|28.7|                   0.532| 22|      0|\n",
            "|         10|    108|           66|            0|      0|32.4|                   0.272| 42|      1|\n",
            "|          0|    102|           75|           23|      0| 0.0|                   0.572| 21|      0|\n",
            "|          4|    114|           65|            0|      0|21.9|                   0.432| 37|      0|\n",
            "|          6|    104|           74|           18|    156|29.9|                   0.722| 41|      1|\n",
            "|          6|    134|           70|           23|    130|35.4|                   0.542| 29|      1|\n",
            "|          6|     85|           78|            0|      0|31.2|                   0.382| 42|      0|\n",
            "|          3|    111|           62|            0|      0|22.6|                   0.142| 21|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### filter by condition"
      ],
      "metadata": {
        "id": "VRnBWgLbPwji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filt(dataframe,condition:str):\n",
        "    \"\"\" return all row of dataframe as dataframe that filter by condition \n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "\n",
        "            columns(str) : columns of dataframe\n",
        "            \n",
        "                   \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "              dataframe_new(:class:`DataFrame): dataframe of the value\n",
        "              \n",
        "        Example:\n",
        "        --------------\n",
        "        dataframe_new = filt (df,df[\"Ward\"]==\"value\") \n",
        "\n",
        "              \"\"\"\n",
        "        \n",
        "        \n",
        "    dataframe_new=dataframe.filter(condition)\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "sLlzhdmNPTn1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filt(df,df[\"SkinThickness\"]==\"0\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDsco8EUPa5Y",
        "outputId": "c85c24ac-dcf6-48f7-bb3b-fa62ab7fd878"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
            "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
            "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
            "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
            "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1|\n",
            "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
            "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|      1|\n",
            "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
            "|          8|     99|           84|            0|      0|35.4|                   0.388| 50|      0|\n",
            "|          7|    196|           90|            0|      0|39.8|                   0.451| 41|      1|\n",
            "|          7|    147|           76|            0|      0|39.4|                   0.257| 43|      1|\n",
            "|          5|    117|           92|            0|      0|34.1|                   0.337| 38|      0|\n",
            "|          6|     92|           92|            0|      0|19.9|                   0.188| 28|      0|\n",
            "|         11|    138|           76|            0|      0|33.2|                    0.42| 35|      0|\n",
            "|          7|    133|           84|            0|      0|40.2|                   0.696| 37|      0|\n",
            "|          7|    159|           64|            0|      0|27.4|                   0.294| 40|      0|\n",
            "|          1|    146|           56|            0|      0|29.7|                   0.564| 29|      0|\n",
            "|          7|    105|            0|            0|      0| 0.0|                   0.305| 24|      0|\n",
            "|          0|    146|           82|            0|      0|40.5|                   1.781| 44|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sort data"
      ],
      "metadata": {
        "id": "_iFKv_epP97Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### count of data in column"
      ],
      "metadata": {
        "id": "kqJdg3bOQXqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def groupbydesc(dataframe,columnname:str):\n",
        "  \"\"\" return  a sorted dataframe by  columnname\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "\n",
        "            columnname(str):select the column\n",
        "        Returns:\n",
        "        --------------\n",
        "            df_sorted (:class:`DataFrame) : new sorted dataframe \n",
        "            \n",
        "\n",
        "            \"\"\"\n",
        "  from pyspark.sql.functions import col\n",
        "  df_sorted = dataframe.groupby(columnname).count().orderBy(col(\"count\").desc())\n",
        "  return df_sorted"
      ],
      "metadata": {
        "id": "2ZoTghkmPqZ3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groupbydesc(df,\"Glucose\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVlDd8MaQHRQ",
        "outputId": "884c15ea-e379-4dcc-d165-8f0961061f74"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|Glucose|count|\n",
            "+-------+-----+\n",
            "|    100|   17|\n",
            "|     99|   17|\n",
            "|    111|   14|\n",
            "|    106|   14|\n",
            "|    129|   14|\n",
            "|    125|   14|\n",
            "|    108|   13|\n",
            "|    112|   13|\n",
            "|    105|   13|\n",
            "|    102|   13|\n",
            "|     95|   13|\n",
            "|    122|   12|\n",
            "|    109|   12|\n",
            "|    128|   11|\n",
            "|    117|   11|\n",
            "|    120|   11|\n",
            "|    107|   11|\n",
            "|    119|   11|\n",
            "|    114|   11|\n",
            "|    124|   11|\n",
            "+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ascending or descending sort data "
      ],
      "metadata": {
        "id": "5k8hYO3aQ1nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sortascending(dataframe,coloumes:str,ascending:bool):\n",
        "    \"\"\" return all sorted  dataframe with  ascending or descending method\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "\n",
        "            columns(str) : columns of dataframe\n",
        "            \n",
        "            ascending(bool): if ascending equal to true it's sorted by ascending if it's equal to False sorted descending\n",
        "            \n",
        "                   \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_asc (:class:`DataFrame) : dataframe of sort value\"\"\"\n",
        "\n",
        "    dataframe_asc = dataframe.orderBy(coloumes,ascending=ascending) \n",
        "    return dataframe_asc"
      ],
      "metadata": {
        "id": "naFAkNMUQLvZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sortascending(df,\"BloodPressure\",False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arrg4Ad7Qm3g",
        "outputId": "d8a26251-7225-4574-e9c6-d7d84d997157"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          1|     96|          122|            0|      0|22.4|                   0.207| 27|      0|\n",
            "|         13|    158|          114|            0|      0|42.3|                   0.257| 44|      1|\n",
            "|          9|    171|          110|           24|    240|45.4|                   0.721| 54|      1|\n",
            "|          0|    129|          110|           46|    130|67.1|                   0.319| 26|      1|\n",
            "|          4|    189|          110|           31|      0|28.5|                    0.68| 37|      0|\n",
            "|          5|    103|          108|           37|      0|39.2|                   0.305| 65|      0|\n",
            "|          5|    137|          108|            0|      0|48.8|                   0.227| 37|      1|\n",
            "|         11|    127|          106|            0|      0|39.0|                    0.19| 51|      0|\n",
            "|         10|     68|          106|           23|     49|35.5|                   0.285| 47|      0|\n",
            "|          8|    167|          106|           46|    231|37.6|                   0.165| 43|      1|\n",
            "|          0|    189|          104|           25|      0|34.3|                   0.435| 41|      1|\n",
            "|          5|    162|          104|            0|      0|37.7|                   0.151| 52|      1|\n",
            "|          1|    133|          102|           28|    140|32.8|                   0.234| 45|      1|\n",
            "|          8|    105|          100|           36|      0|43.3|                   0.239| 45|      1|\n",
            "|          0|     93|          100|           39|     72|43.4|                   1.021| 35|      0|\n",
            "|          3|    123|          100|           35|    240|57.3|                    0.88| 22|      0|\n",
            "|          1|    128|           98|           41|     58|32.0|                   1.321| 33|      1|\n",
            "|          5|    115|           98|            0|      0|52.9|                   0.209| 28|      1|\n",
            "|         10|    115|           98|            0|      0|24.0|                   1.022| 34|      0|\n",
            "|          0|    125|           96|            0|      0|22.5|                   0.262| 21|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### filter columns using is in"
      ],
      "metadata": {
        "id": "4DXuFDxxRw8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isin (dataframe,columns:str,value:str):\n",
        "   \"\"\" return  a  dataframe  where the columns contain Specific  value\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe\n",
        "\n",
        "            columns(str) : columns of dataframe\n",
        "            \n",
        "            value(str): value in columns\n",
        "                   \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : datafram contain Specific  value\"\"\"\n",
        "   dataframe_new = dataframe[dataframe[columns].isin(value)]\n",
        "   return dataframe_new"
      ],
      "metadata": {
        "id": "veRfZggtQwYd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isin(df,\"BloodPressure\",\"72\").show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ANPQBPqRL69",
        "outputId": "7f94d736-d476-422a-895f-7c2a2acc6e0e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          4|    111|           72|           47|    207|37.1|                    1.39| 56|      1|\n",
            "|          8|    133|           72|         null|   null|32.9|                    0.27| 39|      1|\n",
            "|          5|     95|           72|           33|   null|37.7|                    0.37| 27|      0|\n",
            "|         13|    106|           72|           54|   null|36.6|                   0.178| 45|      0|\n",
            "|          4|    134|           72|         null|   null|23.8|                   0.277| 60|      1|\n",
            "|          6|    144|           72|           27|    228|33.9|                   0.255| 40|      0|\n",
            "|          1|    163|           72|         null|   null|39.0|                   1.222| 33|      1|\n",
            "|          1|     81|           72|           18|     40|26.6|                   0.283| 24|      0|\n",
            "|          3|    171|           72|           33|    135|33.3|                   0.199| 24|      1|\n",
            "|          5|    105|           72|           29|    325|36.9|                   0.159| 28|      0|\n",
            "|         17|    163|           72|           41|    114|40.9|                   0.817| 47|      1|\n",
            "|          8|    179|           72|           42|    130|32.7|                   0.719| 36|      1|\n",
            "|          6|    103|           72|           32|    190|37.7|                   0.324| 55|      0|\n",
            "|          5|    111|           72|           28|   null|23.9|                   0.407| 27|      0|\n",
            "|          4|    171|           72|         null|   null|43.6|                   0.479| 26|      1|\n",
            "|          5|    108|           72|           43|     75|36.1|                   0.263| 33|      0|\n",
            "|          8|    112|           72|         null|   null|23.6|                    0.84| 58|      0|\n",
            "|          1|    157|           72|           21|    168|25.6|                   0.123| 24|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## join tow dataframe"
      ],
      "metadata": {
        "id": "H3faQFB7UKK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def join(dataframe1,dataframe2,list_coloumes:str,how:str):\n",
        "    \"\"\" return  a  dataframe  combinong two dataframes\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe1(:class:`DataFrame) : select dataframe  number 1\n",
        "\n",
        "            dataframe2(:class:`DataFrame) : select dataframe  number 2\n",
        "\n",
        "            list_coloumes(str) : columns of dataframe\n",
        "            \n",
        "            how(str):   inner', 'outer', 'full', 'fullouter', 'full_outer', \n",
        "                        'leftouter', 'left', 'left_outer', 'rightouter', 'right', \n",
        "                        'right_outer', 'leftsemi', 'left_semi', 'semi', 'leftanti', \n",
        "                        'left_anti', 'anti', 'cross' joins\n",
        "                   \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : combinong dataframe \"\"\"\n",
        "    dataframe_join=dataframe1.join(dataframe2,list_coloumes,how)\n",
        "    return  dataframe_join"
      ],
      "metadata": {
        "id": "qpj-7MWARudW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=select(df,[\"Pregnancies\",\"Glucose\"])\n",
        "df2=select(df,[\"Glucose\",\"Insulin\"])"
      ],
      "metadata": {
        "id": "CfhB7_R6R6xP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join(df1,df2,[\"Glucose\"],how=\"full\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE4Byz5PSrc3",
        "outputId": "0e50b087-3d33-4962-a4a2-dbb573cbf42d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+-------+\n",
            "|Glucose|Pregnancies|Insulin|\n",
            "+-------+-----------+-------+\n",
            "|      0|          1|      0|\n",
            "|      0|          1|     23|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|     23|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|     23|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          1|      0|\n",
            "|      0|          5|      0|\n",
            "|      0|          5|     23|\n",
            "|      0|          5|      0|\n",
            "|      0|          5|      0|\n",
            "|      0|          5|      0|\n",
            "+-------+-----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## columns operation"
      ],
      "metadata": {
        "id": "fGc2KBcXURk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make new column"
      ],
      "metadata": {
        "id": "IEaX-WEiUhwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makecolumn(dataframe,name:str,opration):\n",
        "    \"\"\" return  a new  dataframe  from old dataframe by using opration\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            name(str):  name of new coloumes\n",
        "            opration : opertion on some coloumes  \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe \n",
        "            \n",
        "        Example:\n",
        "        --------------\n",
        "        Create a new column named c1 from twice the value of the ward column . \n",
        "            dataframe_new=dataframe.withColumn(\"c1\",2*dataframe['ward'])    \n",
        "            \"\"\"\n",
        "    dataframe_new=dataframe.withColumn(name,opration)\n",
        "    \n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "Zg55lxxTTbKA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "makecolumn(df,\"opt\",2*df['Pregnancies']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfg7yNW3T6-D",
        "outputId": "9d1497d0-66d1-47ef-f77f-911f37757f1f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|opt|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---+\n",
            "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1| 12|\n",
            "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|  2|\n",
            "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1| 16|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|  2|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|  0|\n",
            "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0| 10|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|  6|\n",
            "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0| 20|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|  4|\n",
            "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1| 16|\n",
            "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|  8|\n",
            "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1| 20|\n",
            "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0| 20|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|  2|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1| 10|\n",
            "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|      1| 14|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|  0|\n",
            "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1| 14|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|  2|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|  2|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### change the type of one coloume\n"
      ],
      "metadata": {
        "id": "GBEMS4KiU_VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def changetype(dataframe,name_coloume:str,datatype:str):\n",
        "    \"\"\" return  a new  dataframe  from old dataframe with changing data type\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            name_coloume(str):  name of new coloumes\n",
        "            datatype : int,float,str \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe \n",
        "            \n",
        "\n",
        "            \"\"\"\n",
        "    from pyspark.sql.functions import col\n",
        "    dataframe_new=dataframe.withColumn(name_coloume,col = col(name_coloume).cast(datatype))\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "LmFIgaa3UHVk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changetype(df,\"SkinThickness\",\"string\").dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpsfE5yyVGya",
        "outputId": "44c9531f-9084-4001-bf58-637d6ae13e53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pregnancies', 'int'),\n",
              " ('Glucose', 'int'),\n",
              " ('BloodPressure', 'int'),\n",
              " ('SkinThickness', 'string'),\n",
              " ('Insulin', 'int'),\n",
              " ('BMI', 'double'),\n",
              " ('DiabetesPedigreeFunction', 'double'),\n",
              " ('Age', 'int'),\n",
              " ('Outcome', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### concat two columns"
      ],
      "metadata": {
        "id": "vQmyeoQ0VgEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concatcolumn(dataframe,column1:str,column2:str,aliasname:str,sep:str):\n",
        "    \"\"\" return  a  dataframe  combinong two dataframes\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            column1(str):  column name 1\n",
        "            column2(str):  column name 2 \n",
        "            aliasname(str) : name of new column \n",
        "            sep(str) : seperator \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe \n",
        "            \n",
        "\n",
        "            \"\"\"\n",
        "    from pyspark.sql.functions import concat_ws\n",
        "    dataframe_new =dataframe.select(concat_ws(sep,dataframe[column1],dataframe[column2]).alias(aliasname))\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "lKNySiG3VYVW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatcolumn(df,\"Pregnancies\",\"Insulin\",\"concat\",\"/\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpHzpsgfVg-o",
        "outputId": "d3b72a74-f06f-4ae7-9cf9-40fb14b03538"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|concat|\n",
            "+------+\n",
            "|   6/0|\n",
            "|   1/0|\n",
            "|   8/0|\n",
            "|  1/94|\n",
            "| 0/168|\n",
            "|   5/0|\n",
            "|  3/88|\n",
            "|  10/0|\n",
            "| 2/543|\n",
            "|   8/0|\n",
            "|   4/0|\n",
            "|  10/0|\n",
            "|  10/0|\n",
            "| 1/846|\n",
            "| 5/175|\n",
            "|   7/0|\n",
            "| 0/230|\n",
            "|   7/0|\n",
            "|  1/83|\n",
            "|  1/96|\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### new column by splite"
      ],
      "metadata": {
        "id": "CQ8kvUOpr5nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spliting(dataframe,column:str,sep:str,aliasname:str):\n",
        "  \"\"\" create  a new dataframe from spliting the old dataframe\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            column(str):  column name \n",
        "            \n",
        "            aliasname(str) : name of new column \n",
        "            sep(str) : seperator \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe \n",
        "            \n",
        "\n",
        "            \"\"\"\n",
        "  from pyspark.sql.functions import split\n",
        "  dataframe_new=dataframe.withColumn(aliasname,split(dataframe[column],sep))\n",
        "  return dataframe_new"
      ],
      "metadata": {
        "id": "aHjZE0pXVuks"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spliting(df,\"Glucose\",\"1\",\"splitcol\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfbLH2YHr8Ww",
        "outputId": "46156991-66a7-4247-9827-9fcf2dc798ff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+--------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|splitcol|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+--------+\n",
            "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|  [, 48]|\n",
            "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|    [85]|\n",
            "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|  [, 83]|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|    [89]|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|  [, 37]|\n",
            "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0| [, , 6]|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|    [78]|\n",
            "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0| [, , 5]|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|  [, 97]|\n",
            "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|  [, 25]|\n",
            "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0| [, , 0]|\n",
            "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1|  [, 68]|\n",
            "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|  [, 39]|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|  [, 89]|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|  [, 66]|\n",
            "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|      1|  [, 00]|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1| [, , 8]|\n",
            "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|  [, 07]|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|  [, 03]|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1| [, , 5]|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct a new dynamic column From two columns \n"
      ],
      "metadata": {
        "id": "ZJXJ1F7qwG95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newcolumn(dataframe,newcolumnname:str,column1:str,column2:str):\n",
        "    \"\"\" Construct a new dynamic column From two columns \n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            newcolumnname(str):  column name \n",
        "            \n",
        "            column1(str) : name of  column 1\n",
        "            column2(str) : name of  column 2 \n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe \n",
        "            \n",
        "\n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumnname, F.when((dataframe[column1].isNotNull() & dataframe[column2].isNotNull())\n",
        "                                     , F.concat(dataframe[column1], dataframe[column2])).otherwise(F.lit(None)))\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "g7xzb11swEp5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(newcolumn(df,\"Table\",\"BloodPressure\",\"SkinThickness\"),5,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHxn5BkwyAsa",
        "outputId": "17058457-b1b8-4f6d-e2ea-9f4bc48e5fc1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|Outcome|Table|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "|6          |148    |72           |35           |null   |33.6|0.627                   |50 |1      |7235 |\n",
            "|1          |85     |66           |29           |null   |26.6|0.351                   |31 |0      |6629 |\n",
            "|8          |183    |64           |null         |null   |23.3|0.672                   |32 |1      |null |\n",
            "|1          |89     |66           |23           |94     |28.1|0.167                   |21 |0      |6623 |\n",
            "|0          |137    |40           |35           |168    |43.1|2.288                   |33 |1      |4035 |\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove columns"
      ],
      "metadata": {
        "id": "0Yf28BNT7t0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def removecolumns(dataframe,columnsname:str):\n",
        "  \"\"\" remove specific  column in dataframe \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "                       \n",
        "            column(str):  column name \n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with remove a column\n",
        "            \n",
        "  \"\"\"\n",
        "\n",
        "  dataframe_new = dataframe.drop(columnsname)\n",
        "  return dataframe_new"
      ],
      "metadata": {
        "id": "CnrJZHHu7sOH"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removecolumns(df,\"Glucose\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z7iPl4M74z6",
        "outputId": "6befd256-ca4b-4123-9709-884df32b2470"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          1|           66|           29|   null|26.6|                   0.351| 31|      0|\n",
            "|          8|           64|         null|   null|23.3|                   0.672| 32|      1|\n",
            "|          1|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          5|           74|         null|   null|25.6|                   0.201| 30|      0|\n",
            "|          3|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
            "|         10|         null|         null|   null|35.3|                   0.134| 29|      0|\n",
            "|          2|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          8|           96|         null|   null|null|                   0.232| 54|      1|\n",
            "|          4|           92|         null|   null|37.6|                   0.191| 30|      0|\n",
            "|         10|           74|         null|   null|38.0|                   0.537| 34|      1|\n",
            "|         10|           80|         null|   null|27.1|                   1.441| 57|      0|\n",
            "|          1|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
            "|          5|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          7|         null|         null|   null|30.0|                   0.484| 32|      1|\n",
            "|          0|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
            "|          7|           74|         null|   null|29.6|                   0.254| 31|      1|\n",
            "|          1|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
            "|          1|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
            "+-----------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80c1fb71"
      },
      "source": [
        "### remove other columns of  dataframe\n",
        "if specefic column doesn't have the character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "fed31307"
      },
      "outputs": [],
      "source": [
        "def removecontain(dataframe,column:str,character:str):\n",
        "      \n",
        "    \"\"\" remove other columns of  dataframe if specefic column doesn't have the character\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "                       \n",
        "            column(str):  column name \n",
        "\n",
        "            character(str): specific character name\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with remove  columns\n",
        "            \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    dataframe = dataframe.filter(dataframe[column].contains(character))\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "removecontain(df,\"BloodPressure\",\"72\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M77i_Lz78j62",
        "outputId": "20f629a5-a98c-4c23-f4f1-0ef1ede6cfee"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          4|    111|           72|           47|    207|37.1|                    1.39| 56|      1|\n",
            "|          8|    133|           72|         null|   null|32.9|                    0.27| 39|      1|\n",
            "|          5|     95|           72|           33|   null|37.7|                    0.37| 27|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if the column doesn't start with a specific character"
      ],
      "metadata": {
        "id": "kZF8plb2_W3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def removestart(dataframe,column,character:str):\n",
        "          \n",
        "    \"\"\" remove other columns of dataframe  if the column doesn't start with a specific character\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "                       \n",
        "            column(str):  column name \n",
        "\n",
        "            character(str): specific character name\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with remove  columns\n",
        "            \n",
        "    \"\"\"\n",
        "\n",
        "    dataframe = dataframe.filter(dataframe[column].startswith(character))\n",
        "    return dataframe\n",
        "    "
      ],
      "metadata": {
        "id": "TTb_PAv590IM"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removestart(df,\"BloodPressure\",\"7\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UWvHKmw91G7",
        "outputId": "a81cd48e-de05-4c8e-a7f3-60e3b316e41c"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeend(dataframe,column,character:str):\n",
        "              \n",
        "    \"\"\" remove whole dataframe if it doesn't end with a specific character\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "                       \n",
        "            column(str):  column name \n",
        "\n",
        "            character(str): specific character name\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with remove  columns\n",
        "            \n",
        "    \"\"\"\n",
        "    dataframe = dataframe.filter(dataframe[column].endswith(character))\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "FRCe1FEh_qTo"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removeend(df,\"BloodPressure\",\"2\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKlyrMvpAM7D",
        "outputId": "cdbe8b01-7841-43bc-b2ac-d00b9e2e458e"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|         13|    145|           82|           19|    110|22.2|                   0.245| 57|      0|\n",
            "|          5|    117|           92|         null|   null|34.1|                   0.337| 38|      0|\n",
            "|          6|     92|           92|         null|   null|19.9|                   0.188| 28|      0|\n",
            "|          4|    111|           72|           47|    207|37.1|                    1.39| 56|      1|\n",
            "|          7|    106|           92|           18|   null|22.7|                   0.235| 48|      0|\n",
            "|          0|    146|           82|         null|   null|40.5|                   1.781| 44|      0|\n",
            "|          8|    133|           72|         null|   null|32.9|                    0.27| 39|      1|\n",
            "|          5|     44|           62|         null|   null|25.0|                   0.587| 36|      0|\n",
            "|          2|    109|           92|         null|   null|42.7|                   0.845| 54|      0|\n",
            "|          5|     95|           72|           33|   null|37.7|                    0.37| 27|      0|\n",
            "|         13|    106|           72|           54|   null|36.6|                   0.178| 45|      0|\n",
            "|          4|    134|           72|         null|   null|23.8|                   0.277| 60|      1|\n",
            "|          2|    142|           82|           18|     64|24.7|                   0.761| 21|      0|\n",
            "|          6|    144|           72|           27|    228|33.9|                   0.255| 40|      0|\n",
            "|          2|     92|           62|           28|   null|31.6|                    0.13| 24|      0|\n",
            "|          1|    163|           72|         null|   null|39.0|                   1.222| 33|      1|\n",
            "|          1|     81|           72|           18|     40|26.6|                   0.283| 24|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writte sql Query for dataframe"
      ],
      "metadata": {
        "id": "8XJI-bUI7xRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createQuery(dataframe,name:str,Query:str):\n",
        "   \"\"\" Construct a new datafram(table) with sql Query\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            name(str):   table name\n",
        "            Query(str): sql Query\n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            sparksql (:class:`DataFrame) : new dataframe\n",
        "\n",
        "\n",
        "\n",
        "          Examples\n",
        "        --------\n",
        "        >>> df.createOrReplaceTempView(\"people\")\n",
        "        >>> df2 = df.filter(df.age > 3)\n",
        "        >>> df2.createOrReplaceTempView(\"people\")\n",
        "        >>> df3 = spark.sql(\"select * from people\")\n",
        "        >>> sorted(df3.collect()) == sorted(df2.collect())\n",
        "        True\n",
        "        >>> spark.catalog.dropTempView(\"people\")\n",
        "        \"\"\"\n",
        "   dataframe.createOrReplaceTempView(name)\n",
        "   sparksql=spark.sql(Query)\n",
        "   return sparksql"
      ],
      "metadata": {
        "id": "usPkdt8fwy0t"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(createQuery(df,\"Table\",\"select * from Table where Outcome=1\"),5,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2IeZY14wR5J",
        "outputId": "b7230fdd-c0ea-413c-e8d5-66b3e70aa9bb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI |DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|6          |148    |72           |35           |null   |33.6|0.627                   |50 |1      |\n",
            "|8          |183    |64           |null         |null   |23.3|0.672                   |32 |1      |\n",
            "|0          |137    |40           |35           |168    |43.1|2.288                   |33 |1      |\n",
            "|3          |78     |50           |32           |88     |31.0|0.248                   |26 |1      |\n",
            "|2          |197    |70           |45           |543    |30.5|0.158                   |53 |1      |\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## handeling null value\n",
        "according to the information of this dataset all zero value in columns are considered null value except Pregnancies column"
      ],
      "metadata": {
        "id": "NI8NKxHmuKb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replacewithnull(dataframe,specificvalue:Union[int,str],columnsname:str):\n",
        "    \n",
        "  \"\"\" replace specific value  column in dataframe with null value\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            specificvalue(int,str) : specific value \n",
        "            \n",
        "            column(list,otional):  column name \n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with specific value\n",
        "            \n",
        "  \"\"\"\n",
        "  dataframe_new = dataframe.replace({specificvalue: None}, subset=[columnsname])\n",
        "  return dataframe_new"
      ],
      "metadata": {
        "id": "TFCE8GT7tzBH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in df.columns[1:-1]:\n",
        "  df=replacewithnull(df,0,item)\n"
      ],
      "metadata": {
        "id": "vJkmNrexuHGl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(df,5,True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZN3Xgg_vFRF",
        "outputId": "478c44bc-6084-4f77-9a07-a5b2818ceedf"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### list of null value count"
      ],
      "metadata": {
        "id": "6kF4UjhMvYEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def null_value_calc(dataframe)->list:\n",
        "  \"\"\" return  a  list of null value\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "            (null_columns_counts) (list) : list of null value\n",
        "            \n",
        "\n",
        "            \"\"\"\n",
        "  from pyspark.sql.functions import col\n",
        "  null_columns_counts=[]\n",
        "  numrows=dataframe.count()\n",
        "  for k in dataframe.columns:\n",
        "    nullrows=dataframe.where(col(k).isNull()).count()\n",
        "    if (nullrows>0):\n",
        "      temp = k,nullrows,(nullrows/numrows)*100\n",
        "      null_columns_counts.append(temp)\n",
        "  return (null_columns_counts)"
      ],
      "metadata": {
        "id": "bYmwDXjkvG5q"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_value_calc(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTFA7Vj8vURf",
        "outputId": "d160b4b4-e099-4e89-9330-cd3898691dfd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Glucose', 5, 0.6510416666666667),\n",
              " ('BloodPressure', 35, 4.557291666666666),\n",
              " ('SkinThickness', 227, 29.557291666666668),\n",
              " ('Insulin', 374, 48.69791666666667),\n",
              " ('BMI', 11, 1.4322916666666665)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replace all nulls with a specific value\n"
      ],
      "metadata": {
        "id": "dsVfl31Ayr2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replacenull(dataframe,columns:str,newvalue:str):\n",
        "    \"\"\" replace all missing data with optional value \n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newvalue(str) : optional value\n",
        "\n",
        "            columns(str) : name of  column\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with missing replace \n",
        "            \n",
        "\n",
        "        \"\"\"\n",
        "    dataframe = dataframe.fillna({columns: newvalue})\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "4u9YWt3Yvdu4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replacenull(df,\"Insulin\",\"5\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znEcpdbgyuw-",
        "outputId": "96a2ff19-a2b7-403e-f5da-e9fbb7976108"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|      5|33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|      5|26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|         null|      5|23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|         null|      5|25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
            "|         10|    115|         null|         null|      5|35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|         null|      5|null|                   0.232| 54|      1|\n",
            "|          4|    110|           92|         null|      5|37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|         null|      5|38.0|                   0.537| 34|      1|\n",
            "|         10|    139|           80|         null|      5|27.1|                   1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          7|    100|         null|         null|      5|30.0|                   0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
            "|          7|    107|           74|         null|      5|29.6|                   0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### find basic statistic parameter to replace with null values"
      ],
      "metadata": {
        "id": "2u6e401rzgi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findstatistict(dataframe,column:str)->dict:\n",
        "    \"\"\" return basic statistic parameter \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "                       \n",
        "            column(str):  column name \n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            avg(int): average of the column\n",
        "\n",
        "            stddev(int): standard deviation of the column\n",
        "\n",
        "            min(int): minimum of the column\n",
        "\n",
        "            max(int): maximum of the column\n",
        "\n",
        "            q1(int): quartile first of the column\n",
        "\n",
        "            q2(int): quartile second of the column\n",
        "\n",
        "            q3(int): quartile third of the column\n",
        "            \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    avg=eval(dataframe.summary().select(\"summary\",column).collect()[1][1])\n",
        "    stddev=eval(dataframe.summary().select(\"summary\",column).collect()[2][1])\n",
        "    min=eval(dataframe.summary().select(\"summary\",column).collect()[3][1])\n",
        "    max=eval(dataframe.summary().select(\"summary\",column).collect()[7][1])\n",
        "    q1=eval(dataframe.summary().select(\"summary\",column).collect()[4][1])\n",
        "    q2=eval(dataframe.summary().select(\"summary\",column).collect()[5][1])\n",
        "    q3=eval(dataframe.summary().select(\"summary\",column).collect()[6][1])\n",
        "\n",
        "    base={\"avg\":avg,\"stddev\":stddev,\"min\":min,\"max\":max,\"quartile1\":q1,\"quartile2\":q2,\"quartile3\":q3}\n",
        "    return base\n"
      ],
      "metadata": {
        "id": "n6NfLwDpzSax"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in df.columns[1:-1]:\n",
        "  print(item,\": \",findstatistict(df,item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n31fBaxAzmpG",
        "outputId": "f95f3da6-f99c-4b7b-f88d-2486dd33da8b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glucose :  {'avg': 121.6867627785059, 'stddev': 30.53564107280403, 'min': 44, 'max': 199, 'quartile1': 99, 'quartile2': 117, 'quartile3': 141}\n",
            "BloodPressure :  {'avg': 72.40518417462484, 'stddev': 12.382158210105265, 'min': 24, 'max': 122, 'quartile1': 64, 'quartile2': 72, 'quartile3': 80}\n",
            "SkinThickness :  {'avg': 29.153419593345657, 'stddev': 10.476982369987208, 'min': 7, 'max': 99, 'quartile1': 22, 'quartile2': 29, 'quartile3': 36}\n",
            "Insulin :  {'avg': 155.5482233502538, 'stddev': 118.77585518724517, 'min': 14, 'max': 846, 'quartile1': 76, 'quartile2': 125, 'quartile3': 190}\n",
            "BMI :  {'avg': 32.45746367239099, 'stddev': 6.924988332105911, 'min': 18.2, 'max': 67.1, 'quartile1': 27.5, 'quartile2': 32.3, 'quartile3': 36.6}\n",
            "DiabetesPedigreeFunction :  {'avg': 0.4718763020833327, 'stddev': 0.331328595012775, 'min': 0.078, 'max': 2.42, 'quartile1': 0.243, 'quartile2': 0.371, 'quartile3': 0.626}\n",
            "Age :  {'avg': 33.240885416666664, 'stddev': 11.760231540678689, 'min': 21, 'max': 81, 'quartile1': 24, 'quartile2': 29, 'quartile3': 41}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fill all nulls with a specific value"
      ],
      "metadata": {
        "id": "e9VK608zzBWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fillnull(dataframe,newvalue:Union[str,int],subset:list):\n",
        "  \"\"\" replace all missing data with optional value for entire dataframe\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newvalue(str,int) : optional value\n",
        "\n",
        "            columns(str) : name of  column\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with missing replace \n",
        "            \n",
        "\n",
        "        \"\"\"\n",
        "  dataframe_new=dataframe.na.fill(newvalue,subset)\n",
        "  return dataframe_new"
      ],
      "metadata": {
        "id": "gEFHo1IQy5Rx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fillnull(df,72.40518417462484,df.columns[1:-1]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCymGsmnzFEA",
        "outputId": "b27108ce-3427-4630-d5cd-33505789b054"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+-----------------+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|              BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+-----------------+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|     72|             33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|     72|             26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|           72|     72|             23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|             28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|             43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|           72|     72|             25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|             31.0|                   0.248| 26|      1|\n",
            "|         10|    115|           72|           72|     72|             35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|             30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|           72|     72|72.40518417462484|                   0.232| 54|      1|\n",
            "|          4|    110|           92|           72|     72|             37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|           72|     72|             38.0|                   0.537| 34|      1|\n",
            "|         10|    139|           80|           72|     72|             27.1|                   1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|             30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|             25.8|                   0.587| 51|      1|\n",
            "|          7|    100|           72|           72|     72|             30.0|                   0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|             45.8|                   0.551| 31|      1|\n",
            "|          7|    107|           74|           72|     72|             29.6|                   0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|             43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|             34.6|                   0.529| 32|      1|\n",
            "+-----------+-------+-------------+-------------+-------+-----------------+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###drop null values\n",
        "How and Thresh and Subset is optional"
      ],
      "metadata": {
        "id": "7vM-nlDE1rMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dropnnull(dataframe,thresh:int=None,how:str=\"any\",subset:list=None):\n",
        "  \"\"\" drop all missing data column in dataframe\n",
        "            \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            thresh(int,optional) : optional value\n",
        "\n",
        "            how(str,optional) : include (any, all)\n",
        "            \n",
        "            subset(list,optional): list of the column\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with drop column \n",
        "            \n",
        "  \"\"\"\n",
        "  dataframe_new=dataframe.na.drop(how,thresh=thresh,subset=subset)\n",
        "  return dataframe_new"
      ],
      "metadata": {
        "id": "l3bg-N6U1Hxi"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropnnull(df).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-os1URT1ukS",
        "outputId": "af359290-2da6-4ea1-d8b1-a4fd8685900d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
            "|          3|    126|           88|           41|    235|39.3|                   0.704| 27|      0|\n",
            "|         11|    143|           94|           33|    146|36.6|                   0.254| 51|      1|\n",
            "|         10|    125|           70|           26|    115|31.1|                   0.205| 41|      1|\n",
            "|          1|     97|           66|           15|    140|23.2|                   0.487| 22|      0|\n",
            "|         13|    145|           82|           19|    110|22.2|                   0.245| 57|      0|\n",
            "|          3|    158|           76|           36|    245|31.6|                   0.851| 28|      1|\n",
            "|          3|     88|           58|           11|     54|24.8|                   0.267| 22|      0|\n",
            "|          4|    103|           60|           33|    192|24.0|                   0.966| 33|      0|\n",
            "|          4|    111|           72|           47|    207|37.1|                    1.39| 56|      1|\n",
            "|          3|    180|           64|           25|     70|34.0|                   0.271| 26|      0|\n",
            "|          9|    171|          110|           24|    240|45.4|                   0.721| 54|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf769bd"
      },
      "source": [
        "### impute null data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57ac88e7"
      },
      "source": [
        "#### avarage strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "b616f0ab"
      },
      "outputs": [],
      "source": [
        "def imputnullavg(dataframe,inputCols:list,outputCols:list):   \n",
        "    \"\"\" return a dataframe  with imputing null value with average \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            inputCols(list) : name of input columns \n",
        "\n",
        "            outputCols(list) : name of output columns \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe   with imputing null value with average \n",
        "            \n",
        "            \"\"\"\n",
        "    from pyspark.ml.feature import Imputer\n",
        "    a= Imputer(inputCols=inputCols,outputCols=outputCols)\n",
        "    a.setStrategy(\"mean\")\n",
        "    dataframe = a.fit(dataframe).transform(dataframe)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_avg=imputnullavg(df,df.columns[1:-1],df.columns[1:-1])"
      ],
      "metadata": {
        "id": "u1F6zHikT8zu"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_avg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Latf2nDMcjyc",
        "outputId": "60157952-00d6-4059-8f5e-2f9b3bc9d181"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+-----------------+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|              BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+-----------------+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|    155|             33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|    155|             26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|           29|    155|             23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|             28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|             43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|           29|    155|             25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|             31.0|                   0.248| 26|      1|\n",
            "|         10|    115|           72|           29|    155|             35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|             30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|           29|    155|32.45746367239099|                   0.232| 54|      1|\n",
            "|          4|    110|           92|           29|    155|             37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|           29|    155|             38.0|                   0.537| 34|      1|\n",
            "|         10|    139|           80|           29|    155|             27.1|                   1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|             30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|             25.8|                   0.587| 51|      1|\n",
            "|          7|    100|           72|           29|    155|             30.0|                   0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|             45.8|                   0.551| 31|      1|\n",
            "|          7|    107|           74|           29|    155|             29.6|                   0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|             43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|             34.6|                   0.529| 32|      1|\n",
            "+-----------+-------+-------------+-------------+-------+-----------------+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36f7b1bd"
      },
      "source": [
        "#### median strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "e353cbb7"
      },
      "outputs": [],
      "source": [
        "def imputnullmedian(dataframe,inputCols:list,outputCols:list):   \n",
        "    \"\"\" return a dataframe  with imputing null value with median \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            inputCols(str) : name of input columns \n",
        "\n",
        "            outputCols(str) : name of output columns \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe   with imputing null value with median \n",
        "            \n",
        "            \"\"\"\n",
        "    from pyspark.ml.feature import Imputer\n",
        "    a= Imputer(inputCols=inputCols,outputCols=outputCols)\n",
        "    a.setStrategy(\"median\")\n",
        "    dataframe=a.fit(dataframe).transform(dataframe)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## we select median Strategy"
      ],
      "metadata": {
        "id": "upVHR75ZdAFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=imputnullmedian(df,df.columns[1:-1],df.columns[1:-1])"
      ],
      "metadata": {
        "id": "svJR6Ru6USqu"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVVznz5wUeSn",
        "outputId": "4c27b7a0-8695-4e5d-d8c1-896534d2fdfe"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|    125|33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|    125|26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|           29|    125|23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|           29|    125|25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
            "|         10|    115|           72|           29|    125|35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|           29|    125|32.3|                   0.232| 54|      1|\n",
            "|          4|    110|           92|           29|    125|37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|           29|    125|38.0|                   0.537| 34|      1|\n",
            "|         10|    139|           80|           29|    125|27.1|                   1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          7|    100|           72|           29|    125|30.0|                   0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
            "|          7|    107|           74|           29|    125|29.6|                   0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4673af68"
      },
      "source": [
        "## Number Operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cadb8e1"
      },
      "source": [
        "### Round the number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "4afee0d6"
      },
      "outputs": [],
      "source": [
        "def roundnumber(dataframe,newcolumn:str,column:str,scale:int):\n",
        "    \"\"\" return round of integer columns\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            column(str):   column name\n",
        "\n",
        "            scale(int): a scale of rounding\n",
        "\n",
        "\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with  with a round of a columns\n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, F.round(dataframe[column], scale))\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roundnumber(df,\"round\",\"DiabetesPedigreeFunction\",1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncfUekC0E_q1",
        "outputId": "f73d6ef5-7a01-457d-c08b-690232761162"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|round|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|  0.6|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|  0.4|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|  0.7|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|  0.2|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|  2.3|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|  0.2|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|  0.2|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|  0.1|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|  0.2|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|  0.2|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|  0.2|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|  0.5|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|  1.4|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|  0.4|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|  0.6|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|  0.5|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|  0.6|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|  0.3|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|  0.2|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|  0.5|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "271cba96"
      },
      "source": [
        "### Floor of the number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "730dbfe9"
      },
      "outputs": [],
      "source": [
        "def floarnumber(dataframe,newcolumn:str,column:str):\n",
        "    \"\"\" return floor of integer columns\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            column(str):   column name\n",
        "\n",
        "            scale(int): a scale of rounding\n",
        "\n",
        "\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with  with a round of a columns\n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, F.floor(dataframe[column]))\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "floarnumber(df,\"floor\",\"DiabetesPedigreeFunction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqdtCXuhFq7b",
        "outputId": "fb45ceef-ecb2-4536-e19a-2a58fe41cc73"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|floor|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|    0|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|    0|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|    0|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|    0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|    2|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|    0|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|    0|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|    0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|    0|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|    0|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|    0|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|    0|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|    1|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|    0|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|    0|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|    0|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|    0|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|    0|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|    0|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|    0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b77b923a"
      },
      "source": [
        "### Ceiling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "7df803a3"
      },
      "outputs": [],
      "source": [
        "def Ceilingnumber(dataframe,newcolumn:str,column:str):\n",
        "    \"\"\" return Ceilin of integer columns\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            column(str):   column name\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with Ceilin a columns\n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, F.ceil(dataframe[column]))\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ceilingnumber(df,\"ceil\",\"DiabetesPedigreeFunction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QZ09-ASGNqp",
        "outputId": "48fb2717-8784-4506-d4b5-df710633e2a5"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+----+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|ceil|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+----+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|   1|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|   1|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|   1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|   1|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|   3|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|   1|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|   1|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|   1|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|   1|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|   1|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|   1|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|   1|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|   2|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|   1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|   1|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|   1|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|   1|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|   1|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|   1|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|   1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6296a3d"
      },
      "source": [
        "### raised to power"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "88eb273c"
      },
      "outputs": [],
      "source": [
        "def powernumber(dataframe,newcolumn:str,column1:str,column2:str):\n",
        "    \"\"\" return a column calculate first column power by second column \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            column1(str): first  column name\n",
        "\n",
        "            column2(str): second  column name\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with a column calculate first column power by second column\n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe = dataframe.withColumn(newcolumn, F.pow(column1,column2))\n",
        "    return dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "powernumber(df,\"power\",\"BMI\",\"DiabetesPedigreeFunction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnSrDCZsHmyW",
        "outputId": "6bd476ee-8025-4c55-a2a9-bb74465ac9ae"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|             power|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1| 9.057633148063402|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|3.1632495465615262|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1| 8.295893707159925|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0| 1.745556680247769|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1| 5491.411566466998|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|1.9189171885374383|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|2.3434608365325658|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|1.6121364987892832|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1| 1.716008262465754|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|              null|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|1.9992213377494032|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1| 7.052511311366106|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|116.12046015274778|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1| 3.876764904567361|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1| 6.739392765738948|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1| 5.187124683260048|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1| 8.225018403916726|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|2.3643300096173037|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|1.9928622704741754|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1| 6.518854027334187|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4f3c000"
      },
      "source": [
        "### Select smallest value out of multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "05a22b6a"
      },
      "outputs": [],
      "source": [
        "def smallestcolumns( dataframe,newcolumn:str,cols:tuple):\n",
        "    \"\"\" return a  smallest value out of multiple columns \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            cols(tuple):   name of the columns\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with a  smallest value out of multiple columns \n",
        "            \"\"\"\n",
        "    a=str(cols)\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, eval(\"F.least\"+a))\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smallestcolumns(df,\"newcolumn\",(\"BMI\",\"DiabetesPedigreeFunction\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYk5Z-pnJEkE",
        "outputId": "781e739d-4e11-450a-c978-33ba0f61e3ca"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|newcolumn|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|    0.627|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|    0.351|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|    0.672|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|    0.167|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|    2.288|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|    0.201|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|    0.248|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|    0.134|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|    0.158|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|    0.232|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|    0.191|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|    0.537|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|    1.441|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|    0.398|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|    0.587|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|    0.484|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|    0.551|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|    0.254|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|    0.183|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|    0.529|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af4e1980"
      },
      "source": [
        "### Select largest value out of multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "00a13fc5"
      },
      "outputs": [],
      "source": [
        "def greatestcolumns( dataframe,newcolumn:str,cols:str):\n",
        "    \"\"\" return a  greatest value out of multiple columns \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe           \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            cols(tuple):   name of the columns\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "            \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with a  greatest value out of multiple columns\n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe = dataframe.withColumn(newcolumn, eval(\"F.greatest\"+str(cols)))\n",
        "    return dataframe\n",
        "                                     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "greatestcolumns(df,\"newcolumn\",(\"BloodPressure\",\"Insulin\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mlvwZ2gL_iC",
        "outputId": "d1d72128-fef9-4291-f6dc-8eb4637e2b2b"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|newcolumn|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|       72|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|       66|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|       64|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|       94|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|      168|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|       74|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|       88|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|     null|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|      543|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|       96|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|       92|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|       74|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|       80|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|      846|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|      175|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|     null|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|      230|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|       74|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|       83|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|       96|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7659e4ec"
      },
      "source": [
        "### Array Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create array out of columns"
      ],
      "metadata": {
        "id": "xWdZBJd1N9C9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "9f5450d4"
      },
      "outputs": [],
      "source": [
        "def creatarray(dataframe,newcolumn:str,cols:tuple):\n",
        "    \"\"\" create array from selected columns\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "            cols(tuple(str)) : name of columns\n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with array column from selected columns\n",
        "            \"\"\"\n",
        "    \n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, eval(\"F.array\"+str(cols)))\n",
        "    return dataframe_new\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_array=creatarray(df,\"newcolumn\",(\"SkinThickness\",\"BloodPressure\"))"
      ],
      "metadata": {
        "id": "rup-lkiEMYE1"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_array.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rp04cVvPIn1",
        "outputId": "cdc0b714-e2bf-4ef9-c9bd-af803f8d568e"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|   newcolumn|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|    [35, 72]|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|    [29, 66]|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|  [null, 64]|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|    [23, 66]|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|    [35, 40]|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|  [null, 74]|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|    [32, 50]|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|[null, null]|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|    [45, 70]|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|  [null, 96]|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|  [null, 92]|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|  [null, 74]|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|  [null, 80]|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|    [23, 60]|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|    [19, 72]|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|[null, null]|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|    [47, 84]|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|  [null, 74]|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|    [38, 30]|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|    [30, 70]|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79a8568c"
      },
      "source": [
        "### Empty Array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "ab2b20d4"
      },
      "outputs": [],
      "source": [
        "def creatarray(dataframe,newcolumn):\n",
        "    \"\"\" create  empty array \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "            \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with a empty array \n",
        "            \"\"\"\n",
        "    \n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, F.array([]))\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creatarray(df,\"newcolumn\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK2k-9N2OGAq",
        "outputId": "989225f4-cedd-42f2-f1bf-63d763a55ab2"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|newcolumn|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|       []|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|       []|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|       []|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|       []|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|       []|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|       []|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|       []|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|       []|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|       []|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|       []|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|       []|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|       []|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|       []|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|       []|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|       []|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|       []|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|       []|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|       []|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|       []|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|       []|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sizearray(dataframe,newcolumn:str,columnarray:str):\n",
        "    \"\"\" return size of array\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            newcolumn(str): new column name \n",
        "\n",
        "            columnarray(str) : name of column array\n",
        "            \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe  \n",
        "            \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    dataframe_new = dataframe.withColumn(newcolumn, F.size(F.col(columnarray)))\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "GRlleGdcOJxM"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizearray(df_array,\"size\",\"newcolumn\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIE_hhEkPLQk",
        "outputId": "0f1a3df9-85d2-4963-bb7e-8ad110310050"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------+----+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|   newcolumn|size|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------+----+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|    [35, 72]|   2|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|    [29, 66]|   2|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|  [null, 64]|   2|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|    [23, 66]|   2|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|    [35, 40]|   2|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|  [null, 74]|   2|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|    [32, 50]|   2|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|[null, null]|   2|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|    [45, 70]|   2|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|  [null, 96]|   2|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|  [null, 92]|   2|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|  [null, 74]|   2|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|  [null, 80]|   2|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|    [23, 60]|   2|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|    [19, 72]|   2|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|[null, null]|   2|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|    [47, 84]|   2|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|  [null, 74]|   2|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|    [38, 30]|   2|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|    [30, 70]|   2|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "804d973c"
      },
      "source": [
        "## Aggregation Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "783995a6"
      },
      "source": [
        "#### Row Count       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "3bb9c23e"
      },
      "outputs": [],
      "source": [
        "def valuecount(dataframe,columname:str)->int:\n",
        "    \"\"\" return count of selected column\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "\n",
        "\n",
        "            columname(str) : name of column \n",
        "            \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            count (int) :  count of selected column \n",
        "            \"\"\"\n",
        "    count=dataframe.select(columname).count()\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valuecount(df,\"BloodPressure\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEQ-nKJHPnDf",
        "outputId": "a62afcda-9e3d-4e85-b90c-6d33cff90444"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mean of column"
      ],
      "metadata": {
        "id": "gcBSQx3zRnEq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "1b62eab8"
      },
      "outputs": [],
      "source": [
        "def meancolumn(dataframe,groupbycolumns:tuple,meancolumns:str):\n",
        "    \"\"\" return mean of selected column\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            groupbycolumns(tuple) : name of columns \n",
        "\n",
        "            meancolumns(str):mean column\n",
        "            \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with mean of selected column\n",
        "            \n",
        "            \"\"\"\n",
        "\n",
        "    dataframe_new=dataframe.groupBy(groupbycolumns).mean(meancolumns)\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meancolumn(df,(df.columns[1:-1]),\"BloodPressure\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdjHGTeMP48D",
        "outputId": "23a66912-005c-4724-e2e9-1ffae200411d"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------+-------+----+------------------------+---+------------------+\n",
            "|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|avg(BloodPressure)|\n",
            "+-------+-------------+-------------+-------+----+------------------------+---+------------------+\n",
            "|    143|           94|           33|    146|36.6|                   0.254| 51|              94.0|\n",
            "|     90|           80|           14|     55|24.4|                   0.249| 24|              80.0|\n",
            "|     84|           68|           30|    106|31.9|                   0.591| 25|              68.0|\n",
            "|     94|           70|           27|    115|43.5|                   0.347| 21|              70.0|\n",
            "|    130|           78|           23|     79|28.4|                   0.323| 34|              78.0|\n",
            "|    197|           70|           99|   null|34.7|                   0.575| 62|              70.0|\n",
            "|    173|           74|         null|   null|36.8|                   0.088| 38|              74.0|\n",
            "|     75|           64|           24|     55|29.7|                    0.37| 33|              64.0|\n",
            "|    149|           68|           29|    127|29.3|                   0.349| 42|              68.0|\n",
            "|    184|           84|           33|   null|35.5|                   0.355| 41|              84.0|\n",
            "|     95|           82|           25|    180|35.0|                   0.233| 43|              82.0|\n",
            "|    126|           78|           27|     22|29.6|                   0.439| 40|              78.0|\n",
            "|     85|           74|           22|   null|29.0|                   1.224| 32|              74.0|\n",
            "|    109|           80|           31|   null|35.9|                   1.127| 43|              80.0|\n",
            "|    118|           70|         null|   null|44.5|                   0.904| 26|              70.0|\n",
            "|    144|           82|           26|    285|32.0|                   0.452| 58|              82.0|\n",
            "|    121|           72|           23|    112|26.2|                   0.245| 30|              72.0|\n",
            "|     61|           82|           28|   null|34.4|                   0.243| 46|              82.0|\n",
            "|     93|           56|           11|   null|22.5|                   0.417| 22|              56.0|\n",
            "|    171|          110|           24|    240|45.4|                   0.721| 54|             110.0|\n",
            "+-------+-------------+-------------+-------+----+------------------------+---+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### max of columns"
      ],
      "metadata": {
        "id": "GTYIgX0dR41i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "2b56c0cd"
      },
      "outputs": [],
      "source": [
        "def maxncloumn(dataframe,groupbycolumns:tuple,maxcolumns:str):\n",
        "    \"\"\" return max of selected column\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            groupbycolumns(tuple) : name of columns \n",
        "\n",
        "            maxcolumns(str):mean column\n",
        "            \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with max of selected column\n",
        "            \n",
        "            \"\"\"\n",
        "    dataframe_new=dataframe.groupBy(groupbycolumns).max(maxcolumns)\n",
        "    return dataframe_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxncloumn(df,(df.columns[1:-3]),\"BloodPressure\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSOjhJ-qP4DT",
        "outputId": "47ec05a3-4b0b-4990-b4dc-75401f69b26f"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------+-------+----+------------------+\n",
            "|Glucose|BloodPressure|SkinThickness|Insulin| BMI|max(BloodPressure)|\n",
            "+-------+-------------+-------------+-------+----+------------------+\n",
            "|    112|           66|         null|   null|37.8|                66|\n",
            "|    146|         null|         null|   null|27.5|              null|\n",
            "|    114|           64|         null|   null|27.4|                64|\n",
            "|     87|           68|           34|     77|37.6|                68|\n",
            "|    136|           84|           35|    130|28.3|                84|\n",
            "|     87|           80|         null|   null|23.2|                80|\n",
            "|    122|           86|         null|   null|34.7|                86|\n",
            "|     94|           65|           22|   null|24.7|                65|\n",
            "|    116|           74|         null|   null|25.6|                74|\n",
            "|    101|           50|           15|     36|24.2|                50|\n",
            "|    100|           68|           25|     71|38.5|                68|\n",
            "|    136|           70|           32|    110|37.1|                70|\n",
            "|     97|           64|           36|    100|36.8|                64|\n",
            "|    107|           88|         null|   null|36.8|                88|\n",
            "|    136|           70|         null|   null|31.2|                70|\n",
            "|    181|           68|           36|    495|30.1|                68|\n",
            "|    173|           78|           39|    185|33.8|                78|\n",
            "|    183|           64|         null|   null|23.3|                64|\n",
            "|    114|           68|           22|   null|28.7|                68|\n",
            "|    146|           92|         null|   null|31.2|                92|\n",
            "+-------+-------------+-------------+-------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### min columns"
      ],
      "metadata": {
        "id": "cREqENTiSNjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mincloumn(dataframe,groupbycolumns:tuple,mincloumns:str):\n",
        "    \"\"\" return min of selected column\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            groupbycolumns(tuple) : name of columns \n",
        "\n",
        "            mincloumns(str):mean column\n",
        "            \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe with min of selected column\n",
        "            \n",
        "            \"\"\"\n",
        "    dataframe_new=dataframe.groupBy(groupbycolumns).min(mincloumns)\n",
        "    return dataframe_new"
      ],
      "metadata": {
        "id": "uofOzoNfR_wx"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mincloumn(df,(df.columns[1:-3]),\"BloodPressure\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJIeTt7ESQBT",
        "outputId": "106d17af-475e-404e-b7e8-a9c4203d7cf8"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------+-------+----+------------------+\n",
            "|Glucose|BloodPressure|SkinThickness|Insulin| BMI|min(BloodPressure)|\n",
            "+-------+-------------+-------------+-------+----+------------------+\n",
            "|    112|           66|         null|   null|37.8|                66|\n",
            "|    146|         null|         null|   null|27.5|              null|\n",
            "|    114|           64|         null|   null|27.4|                64|\n",
            "|     87|           68|           34|     77|37.6|                68|\n",
            "|    136|           84|           35|    130|28.3|                84|\n",
            "|     87|           80|         null|   null|23.2|                80|\n",
            "|    122|           86|         null|   null|34.7|                86|\n",
            "|     94|           65|           22|   null|24.7|                65|\n",
            "|    116|           74|         null|   null|25.6|                74|\n",
            "|    101|           50|           15|     36|24.2|                50|\n",
            "|    100|           68|           25|     71|38.5|                68|\n",
            "|    136|           70|           32|    110|37.1|                70|\n",
            "|     97|           64|           36|    100|36.8|                64|\n",
            "|    107|           88|         null|   null|36.8|                88|\n",
            "|    136|           70|         null|   null|31.2|                70|\n",
            "|    181|           68|           36|    495|30.1|                68|\n",
            "|    173|           78|           39|    185|33.8|                78|\n",
            "|    183|           64|         null|   null|23.3|                64|\n",
            "|    114|           68|           22|   null|28.7|                68|\n",
            "|    146|           92|         null|   null|31.2|                92|\n",
            "+-------+-------------+-------------+-------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "986b8ecd"
      },
      "source": [
        "### Advanced Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "57400b4e"
      },
      "outputs": [],
      "source": [
        "def repartition(dataframe,column:str):\n",
        "    \"\"\" return dataframe  with a new repartition\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : select dataframe        \n",
        "            \n",
        "            column(str) : name of columns \n",
        "\n",
        "          \n",
        "\n",
        "            \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            dataframe_new (:class:`DataFrame) : new dataframe  with a new repartition\n",
        "            \n",
        "            \"\"\"\n",
        "\n",
        "    dataframe_new = dataframe.repartition(dataframe[column])\n",
        "    return dataframe_new\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LzHqwFmSmty",
        "outputId": "a49084f1-d7ed-4288-dace-11c3cba97af2"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|   null|33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|   null|26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|         null|   null|23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|         null|   null|25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
            "|         10|    115|         null|         null|   null|35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|         null|   null|null|                   0.232| 54|      1|\n",
            "|          4|    110|           92|         null|   null|37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|         null|   null|38.0|                   0.537| 34|      1|\n",
            "|         10|    139|           80|         null|   null|27.1|                   1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          7|    100|         null|         null|   null|30.0|                   0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
            "|          7|    107|           74|         null|   null|29.6|                   0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repartition\n",
        "PySpark Repartition provides a full shuffling of data"
      ],
      "metadata": {
        "id": "rpUct2HkTIHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repartition(df,\"Insulin\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzcoCu-vSfgG",
        "outputId": "9d2ee1a3-7cd3-4113-c003-a6cc2abaf745"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          0|    137|           68|           14|    148|24.8|                   0.143| 21|      0|\n",
            "|          0|    106|           70|           37|    148|39.4|                   0.605| 22|      0|\n",
            "|          2|    155|           52|           27|    540|38.7|                    0.24| 25|      1|\n",
            "|          7|    187|           50|           33|    392|33.9|                   0.826| 34|      1|\n",
            "|          3|    113|           50|           10|     85|29.5|                   0.626| 25|      0|\n",
            "|          3|     89|           74|           16|     85|30.4|                   0.551| 38|      0|\n",
            "|          1|     86|           66|           52|     65|41.3|                   0.917| 29|      0|\n",
            "|          2|     88|           74|           19|     53|29.0|                   0.229| 22|      0|\n",
            "|          0|    117|           80|           31|     53|45.2|                   0.089| 24|      0|\n",
            "|          0|    165|           76|           43|    255|47.9|                   0.259| 26|      0|\n",
            "|          3|    111|           90|           12|     78|28.4|                   0.495| 29|      0|\n",
            "|          0|    102|           64|           46|     78|40.6|                   0.496| 21|      0|\n",
            "|          7|    168|           88|           42|    321|38.2|                   0.787| 40|      1|\n",
            "|          1|    193|           50|           16|    375|25.9|                   0.655| 24|      0|\n",
            "|          9|    156|           86|           28|    155|34.3|                   1.189| 42|      1|\n",
            "|          4|    197|           70|           39|    744|36.7|                   2.329| 31|      0|\n",
            "|          7|    133|           88|           15|    155|32.4|                   0.262| 37|      0|\n",
            "|          8|    126|           88|           36|    108|38.5|                   0.349| 49|      0|\n",
            "|          3|    129|           92|           49|    155|36.4|                   0.968| 32|      1|\n",
            "|          4|    127|           88|           11|    155|34.5|                   0.598| 28|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## machine learning"
      ],
      "metadata": {
        "id": "tgVMi_SNdZSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Prep function\n",
        "    \n",
        "def MLClassifierDFPrep(df,input_columns,dependent_var,treat_outliers=True,treat_neg_values=True):\n",
        "\n",
        "    renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType())) \n",
        "    indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") \n",
        "    indexed = indexer.fit(renamed).transform(renamed)\n",
        "\n",
        "    numeric_inputs = []\n",
        "    string_inputs = []\n",
        "    for column in input_columns:\n",
        "        if str(indexed.schema[column].dataType) == 'StringType':\n",
        "            indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \n",
        "            indexed = indexer.fit(indexed).transform(indexed)\n",
        "            new_col_name = column+\"_num\"\n",
        "            string_inputs.append(new_col_name)\n",
        "        else:\n",
        "            numeric_inputs.append(column)\n",
        "            \n",
        "    if treat_outliers == True:\n",
        "        print(\"We are correcting for non normality now!\")\n",
        "        d = {}\n",
        "        for col in numeric_inputs: \n",
        "            d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25) \n",
        "        for col in numeric_inputs:\n",
        "            skew = indexed.agg(skewness(indexed[col])).collect() \n",
        "            skew = skew[0][0]\n",
        "            if skew > 1:\n",
        "                indexed = indexed.withColumn(col, \\\n",
        "                log(when(df[col] < d[col][0],d[col][0])\\\n",
        "                .when(indexed[col] > d[col][1], d[col][1])\\\n",
        "                .otherwise(indexed[col] ) +1).alias(col))\n",
        "                print(col+\" has been treated for positive (right) skewness. (skew =)\",skew,\")\")\n",
        "            elif skew < -1:\n",
        "                indexed = indexed.withColumn(col, \\\n",
        "                exp(when(df[col] < d[col][0],d[col][0])\\\n",
        "                .when(indexed[col] > d[col][1], d[col][1])\\\n",
        "                .otherwise(indexed[col] )).alias(col))\n",
        "                print(col+\" has been treated for negative (left) skewness. (skew =\",skew,\")\")\n",
        "\n",
        "            \n",
        "    minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs]) \n",
        "    min_array = minimums.select(array(numeric_inputs).alias(\"mins\")) \n",
        "    df_minimum = min_array.select(array_min(min_array.mins)).collect() \n",
        "    df_minimum = df_minimum[0][0] \n",
        "\n",
        "    features_list = numeric_inputs + string_inputs\n",
        "    assembler = VectorAssembler(inputCols=features_list,outputCol='features')\n",
        "    output = assembler.transform(indexed).select('features','label')\n",
        "\n",
        "    if df_minimum < 0:\n",
        "        print(\" \")\n",
        "        print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\")\n",
        "        print(\" \")\n",
        "    \n",
        "    if treat_neg_values == True:\n",
        "        print(\"You have opted to correct that by rescaling all your features to a range of 0 to 1\")\n",
        "        print(\" \")\n",
        "        print(\"We are rescaling you dataframe....\")\n",
        "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n",
        "        scalerModel = scaler.fit(output)\n",
        "\n",
        "        scaled_data = scalerModel.transform(output)\n",
        "        final_data = scaled_data.select('label','scaledFeatures')\n",
        "        final_data = final_data.withColumnRenamed('scaledFeatures','features')\n",
        "        print(\"Done!\")\n",
        "\n",
        "    else:\n",
        "        print(\"You have opted not to correct that therefore you will not be able to use to Naive Bayes classifier\")\n",
        "        print(\"We will return the dataframe unscaled.\")\n",
        "        final_data = output\n",
        "    \n",
        "    return final_data"
      ],
      "metadata": {
        "id": "fFlLUHTAdKa3"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZU7d0x6j6zQ"
      },
      "source": [
        "### classification \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixYwQZs3TjQ9"
      },
      "source": [
        "#### MultilayerPerceptronClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "rKI-AdXwTjwx"
      },
      "outputs": [],
      "source": [
        "def MultilayerPerceptronClassifiermodel(features,classes,folds,train,test,input_columns):\n",
        "    \"\"\" return a Multilayer Perceptron Classifier accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return a Multilayer Perceptron Classifier  accuracy\n",
        "              \n",
        "            \n",
        "            \"\"\"  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    classifier=MultilayerPerceptronClassifier()\n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
        "              \n",
        "            # specify layers for the neural network:\n",
        "            # input layer of size features, two intermediate of features+1 and same size as features\n",
        "            # and output of size number of classes\n",
        "            # Note: crossvalidator cannot be used here\n",
        "            features_count = len(features[0][0])\n",
        "            layers = [features_count, features_count+1, features_count, classes]\n",
        "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
        "            fitModel = MPC_classifier.fit(train)\n",
        "            return fitModel\n",
        "                      \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
        "  \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGSeHHHoZmbU"
      },
      "source": [
        "#### OneVsRest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "4543b496"
      },
      "outputs": [],
      "source": [
        "def OneVsRestmodel(features,classes,folds,train,test,input_columns):\n",
        "    \"\"\" return a One Vs Rest accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return One Vs Rest  accuracy\n",
        "              \n",
        "            \n",
        "            \"\"\"  \n",
        "    from pyspark.ml.classification import OneVsRest,LogisticRegression\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=OneVsRest()\n",
        "    Mtype=\"OneVsRest\"\n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
        "        \n",
        "        if Mtype == \"OneVsRest\":\n",
        "            # instantiate the base classifier.\n",
        "            lr = LogisticRegression()\n",
        "            # instantiate the One Vs Rest Classifier.\n",
        "            OVRclassifier = OneVsRest(classifier=lr)\n",
        "#             fitModel = OVRclassifier.fit(train)\n",
        "            # Add parameters of your choice here:\n",
        "            paramGrid = ParamGridBuilder() \\\n",
        "                .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
        "                .build()\n",
        "            #Cross Validator requires the following parameters:\n",
        "            crossval = CrossValidator(estimator=OVRclassifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=2) # 3 is best practice\n",
        "            # Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "        \n",
        "            # Get Best Model\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\n",
        "            # Extract list of binary models\n",
        "            models = BestModel.models\n",
        "            for model in models:\n",
        "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
        "\n",
        "\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDBEV4lHc5Mb"
      },
      "source": [
        "#### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "WF1pY4Wsc0I4"
      },
      "outputs": [],
      "source": [
        "def LogisticRegressionmodel(features,classes,folds,train,test,input_columns) :\n",
        "    \"\"\" return Logistic Regression accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return Logistic Regression  accuracy\n",
        "              \n",
        "            \n",
        "            \"\"\"  \n",
        "    from pyspark.ml.classification import LogisticRegression\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=LogisticRegression()\n",
        "    def FindMtype(classifier):\n",
        "    \n",
        "        M = classifier\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
        "        \n",
        "\n",
        "\n",
        "       \n",
        "  \n",
        "            # Add parameters of your choice here:\n",
        "            if Mtype in(\"LogisticRegression\"):\n",
        "                paramGrid = (ParamGridBuilder() \\\n",
        "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
        "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
        "                             .build())\n",
        "                \n",
        "\n",
        "            \n",
        "            #Cross Validator requires all of the following parameters:\n",
        "            crossval = CrossValidator(estimator=classifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=folds) # 3 + is best practice\n",
        "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "        \n",
        "       \n",
        "        # Print the coefficients\n",
        "        if Mtype in(\"LogisticRegression\"):\n",
        "            # Get Best Model\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\n",
        "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
        "            print('\\033[1m' + \" Top 20 Coefficients\"+ '\\033[0m')\n",
        "            print(\"You should compares these relative to eachother\")\n",
        "            # Convert from numpy array to list\n",
        "            coeff_array = BestModel.coefficientMatrix.toArray()\n",
        "            coeff_scores = []\n",
        "            for x in coeff_array[0]:\n",
        "                coeff_scores.append(float(x))\n",
        "            # Then zip with input_columns list and create a df\n",
        "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
        "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
        "            # Save the coefficient values and the models\n",
        "            global LR_coefficients\n",
        "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
        "            global LR_BestModel\n",
        "            LR_BestModel = BestModel\n",
        "\n",
        "        \n",
        "   \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU84O559jU_-"
      },
      "source": [
        "#### Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "JT2MH-s9jTk7"
      },
      "outputs": [],
      "source": [
        "def NaiveBayesmodel(features,classes,folds,train,test,input_columns) :\n",
        "    \"\"\" return Naive Bayes accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return Naive Bayes  accuracy\n",
        "              \n",
        "            \"\"\"    \n",
        "    from pyspark.ml.classification import NaiveBayes\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=NaiveBayes()\n",
        "    \n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
        "        \n",
        "        \n",
        "      \n",
        "            if Mtype in(\"NaiveBayes\"):\n",
        "                paramGrid = (ParamGridBuilder() \\\n",
        "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
        "                             .build())\n",
        "                \n",
        "            \n",
        "            \n",
        "          \n",
        "            #Cross Validator requires all of the following parameters:\n",
        "            crossval = CrossValidator(estimator=classifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=folds) # 3 + is best practice\n",
        "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "        \n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "        # Print the coefficients\n",
        "       \n",
        "        if Mtype in(\"LinearSVC\"):\n",
        "            # Get Best Model\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\n",
        "            print(\"Intercept: \" + str(BestModel.intercept))\n",
        "            print('\\033[1m' + \"Top 20 Coefficients\"+ '\\033[0m')\n",
        "            print(\"You should compares these relative to eachother\")\n",
        "#             print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
        "            coeff_array = BestModel.coefficients.toArray()\n",
        "            coeff_scores = []\n",
        "            for x in coeff_array:\n",
        "                coeff_scores.append(float(x))\n",
        "            # Then zip with input_columns list and create a df\n",
        "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
        "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
        "            # Save the coefficient values and the models\n",
        "            global LSVC_coefficients\n",
        "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
        "            global LSVC_BestModel\n",
        "            LSVC_BestModel = BestModel\n",
        "        \n",
        "   \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDOKA4v8_GE1"
      },
      "source": [
        "#### Random Forest Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "qeNGHlfdlLrh"
      },
      "outputs": [],
      "source": [
        "def RandomForestClassifiermodel(features,classes,folds,train,test,input_columns) :\n",
        "    \"\"\" return Random Forest Classifier accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return Random Forest Classifier  accuracy\n",
        "              \n",
        "            \"\"\"\n",
        "    from pyspark.ml.classification import RandomForestClassifier\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=RandomForestClassifier()\n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
        "        \n",
        "       \n",
        "        \n",
        "  \n",
        "\n",
        "            # Add parameters of your choice here:\n",
        "            if Mtype in(\"RandomForestClassifier\"):\n",
        "                paramGrid = (ParamGridBuilder() \\\n",
        "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
        "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
        "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
        "                             .build())\n",
        "                \n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "            #Cross Validator requires all of the following parameters:\n",
        "            crossval = CrossValidator(estimator=classifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=folds) # 3 + is best practice\n",
        "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype,\" Top 20 Feature Importances\"+ '\\033[0m')\n",
        "            print(\"(Scores add up to 1)\")\n",
        "            print(\"Lowest score is the least important\")\n",
        "            print(\" \")\n",
        "            featureImportances = BestModel.featureImportances.toArray()\n",
        "            # Convert from numpy array to list\n",
        "            imp_scores = []\n",
        "            for x in featureImportances:\n",
        "                imp_scores.append(float(x))\n",
        "            # Then zip with input_columns list and create a df\n",
        "            result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
        "            print(result.orderBy(result[\"score\"].desc()).show(truncate=False))\n",
        "            \n",
        "\n",
        "            if Mtype in(\"RandomForestClassifier\"):\n",
        "                global RF_featureimportances\n",
        "                RF_featureimportances = BestModel.featureImportances.toArray()\n",
        "                global RF_BestModel\n",
        "                RF_BestModel = BestModel\n",
        "\n",
        "  \n",
        "        \n",
        "   \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92A9IEkwWsG"
      },
      "source": [
        "#### Decision Tree Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "WOVS6fNfwVXq"
      },
      "outputs": [],
      "source": [
        "def DecisionTreeClassifiermodel(features,classes,folds,train,test,input_columns) :\n",
        "    \"\"\" return  Decision Tree Classifier accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return Decision Tree Classifier  accuracy\n",
        "              \n",
        "            \"\"\"\n",
        "    from pyspark.ml.classification import DecisionTreeClassifier\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=DecisionTreeClassifier()\n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
        "        \n",
        "       \n",
        "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
        "  \n",
        "\n",
        "            \n",
        "            # Add parameters of your choice here:\n",
        "            if Mtype in(\"DecisionTreeClassifier\"):\n",
        "                paramGrid = (ParamGridBuilder() \\\n",
        "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
        "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
        "                             .build())\n",
        "            \n",
        "            #Cross Validator requires all of the following parameters:\n",
        "            crossval = CrossValidator(estimator=classifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=folds) # 3 + is best practice\n",
        "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "\n",
        "\n",
        "            # FEATURE IMPORTANCES\n",
        "            # Estimate of the importance of each feature.\n",
        "            # Each features importance is the average of its importance across all trees \n",
        "            # in the ensemble The importance vector is normalized to sum to 1. \n",
        "            # Get Best Model\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype,\" Top 20 Feature Importances\"+ '\\033[0m')\n",
        "            print(\"(Scores add up to 1)\")\n",
        "            print(\"Lowest score is the least important\")\n",
        "            print(\" \")\n",
        "            featureImportances = BestModel.featureImportances.toArray()\n",
        "            # Convert from numpy array to list\n",
        "            imp_scores = []\n",
        "            for x in featureImportances:\n",
        "                imp_scores.append(float(x))\n",
        "            # Then zip with input_columns list and create a df\n",
        "            result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
        "            print(result.orderBy(result[\"score\"].desc()).show(truncate=False))\n",
        "            \n",
        "            # Save the feature importance values and the models\n",
        "            if Mtype in(\"DecisionTreeClassifier\"):\n",
        "                global DT_featureimportances\n",
        "                DT_featureimportances = BestModel.featureImportances.toArray()\n",
        "                global DT_BestModel\n",
        "                DT_BestModel = BestModel\n",
        "\n",
        "\n",
        "        # Print the coefficients\n",
        "\n",
        "        # Print the Coefficients\n",
        "\n",
        "        \n",
        "   \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAByl7t_EuhB"
      },
      "source": [
        "#### GBTClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "97xjrmO61OHp"
      },
      "outputs": [],
      "source": [
        "def GBTClassifiermodel(features,classes,folds,train,test,input_columns):\n",
        "    \"\"\" return GBT Classifier accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(str) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return GBT Classifier  accuracy\n",
        "              \n",
        "            \"\"\"\n",
        "    from pyspark.ml.classification import GBTClassifier\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=GBTClassifier()\n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
        "        \n",
        "        \n",
        "  \n",
        "\n",
        "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: # These classifiers currently only accept binary classification\n",
        "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
        "            return\n",
        "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
        "  \n",
        "\n",
        "            if Mtype in(\"GBTClassifier\"):\n",
        "                paramGrid = (ParamGridBuilder() \\\n",
        "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
        "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
        "                             .addGrid(classifier.maxIter, [10, 15,50,100])\n",
        "                             .build())\n",
        "                \n",
        "\n",
        "\n",
        "            \n",
        "            #Cross Validator requires all of the following parameters:\n",
        "            crossval = CrossValidator(estimator=classifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=folds) # 3 + is best practice\n",
        "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # FEATURE IMPORTANCES\n",
        "            # Estimate of the importance of each feature.\n",
        "            # Each features importance is the average of its importance across all trees \n",
        "            # in the ensemble The importance vector is normalized to sum to 1. \n",
        "            # Get Best Model\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype,\" Top 20 Feature Importances\"+ '\\033[0m')\n",
        "            print(\"(Scores add up to 1)\")\n",
        "            print(\"Lowest score is the least important\")\n",
        "            print(\" \")\n",
        "            featureImportances = BestModel.featureImportances.toArray()\n",
        "            # Convert from numpy array to list\n",
        "            imp_scores = []\n",
        "            for x in featureImportances:\n",
        "                imp_scores.append(float(x))\n",
        "            # Then zip with input_columns list and create a df\n",
        "            result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
        "            print(result.orderBy(result[\"score\"].desc()).show(truncate=False))\n",
        "            \n",
        "            # Save the feature importance values and the models\n",
        "\n",
        "            if Mtype in(\"GBTClassifier\"):\n",
        "                global GBT_featureimportances\n",
        "                GBT_featureimportances = BestModel.featureImportances.toArray()\n",
        "                global GBT_BestModel\n",
        "                GBT_BestModel = BestModel\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "   \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtYKB_L0umn9"
      },
      "source": [
        "#### Linear SVC model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "cV-tNyktsvnz"
      },
      "outputs": [],
      "source": [
        "def LinearSVCmodel(features,classes,folds,train,test,input_columns):\n",
        "    \"\"\" return Linear SVC accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            features(:class:`DataFrame) : features column       \n",
        "            \n",
        "            classes(int) : number of column target \n",
        "\n",
        "            folds(int) : estimate the skill of the model on new data \n",
        "\n",
        "            train(:class:`DataFrame) : train dataframe \n",
        "            \n",
        "            test(:class:`DataFrame) :   test dataframe \n",
        "            \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return Linear SVC  accuracy\n",
        "              \n",
        "            \"\"\"\n",
        "    from pyspark.ml.classification import LinearSVC\n",
        "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    classifier=LinearSVC()\n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        \n",
        "        return Mtype\n",
        "    \n",
        "    Mtype = FindMtype(classifier)\n",
        "    \n",
        "\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\n",
        "        \n",
        "\n",
        "\n",
        "        if Mtype in(\"LinearSVC\") and classes != 2: # These classifiers currently only accept binary classification\n",
        "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
        "            return\n",
        "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\n",
        "  \n",
        "\n",
        "\n",
        "            if Mtype in(\"LinearSVC\"):\n",
        "                paramGrid = (ParamGridBuilder() \\\n",
        "                             .addGrid(classifier.maxIter, [10, 15]) \\\n",
        "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
        "                             .build())\n",
        "\n",
        "            \n",
        "            #Cross Validator requires all of the following parameters:\n",
        "            crossval = CrossValidator(estimator=classifier,\n",
        "                                      estimatorParamMaps=paramGrid,\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\n",
        "                                      numFolds=folds) # 3 + is best practice\n",
        "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
        "            fitModel = crossval.fit(train)\n",
        "            return fitModel\n",
        "    \n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\n",
        "    \n",
        "    # Print feature selection metrics\n",
        "    if fitModel is not None:\n",
        "        \n",
        "\n",
        "        if Mtype in(\"LinearSVC\"):\n",
        "            # Get Best Model\n",
        "            BestModel = fitModel.bestModel\n",
        "            print(\" \")\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\n",
        "            print(\"Intercept: \" + str(BestModel.intercept))\n",
        "            print('\\033[1m' + \"Top 20 Coefficients\"+ '\\033[0m')\n",
        "            print(\"You should compares these relative to eachother\")\n",
        "#             print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
        "            coeff_array = BestModel.coefficients.toArray()\n",
        "            coeff_scores = []\n",
        "            for x in coeff_array:\n",
        "                coeff_scores.append(float(x))\n",
        "            # Then zip with input_columns list and create a df\n",
        "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\n",
        "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\n",
        "            # Save the coefficient values and the models\n",
        "            global LSVC_coefficients\n",
        "            LSVC_coefficients = BestModel.coefficients.toArray()\n",
        "            global LSVC_BestModel\n",
        "            LSVC_BestModel = BestModel\n",
        "        \n",
        "   \n",
        "    # Set the column names to match the external results dataframe that we will join with later:\n",
        "    columns = ['Classifier', 'Result']\n",
        "    \n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\n",
        "        Mtype = [Mtype] # make this a list\n",
        "        score = [\"N/A\"]\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "    else:\n",
        "        predictions = fitModel.transform(test)\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\",\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\n",
        "        Mtype = [Mtype] # make this a string\n",
        "        score = [str(accuracy)] #make this a string and convert to a list\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\n",
        "        \n",
        "    return result\n",
        "    #Also returns the fit model important scores or p values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLF_KV7fucSj"
      },
      "source": [
        "### test with  or without treat outliers,treat negative values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "P6JDAdfXurOO"
      },
      "outputs": [],
      "source": [
        "def modeltest(dataframe,classifier,dependent_var:str,input_columns:list,trainsplite:int,testsplite:int,seed:int,folds:int,treat_outliers:bool,treat_neg_values:bool):\n",
        "    \"\"\" return all model accuracy \n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : dataframe        \n",
        "            \n",
        "            classifier : name of model incude () \n",
        "\n",
        "            dependent_var(str) : estimate the skill of the model on new data \n",
        "\n",
        "            input_columns(list) : input_columns\n",
        "            \n",
        "            trainsplite(int) :   number train splite\n",
        "\n",
        "            testsplite(int) :   number test splite\n",
        "\n",
        "            seed(int) : seed of train and test\n",
        "            \n",
        "            folds(int) : estimate the skill of the model on new data\n",
        "            \n",
        "            treat_outliers(bool) : fix outliers \n",
        "\n",
        "            treat_neg_values(bool) :fix negative value \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return all  accuracy\n",
        "              \n",
        "            \"\"\"\n",
        "    def FindMtype(classifier):\n",
        "        # Intstantiate Model\n",
        "        M = classifier\n",
        "        # Learn what it is\n",
        "        Mtype = type(M).__name__\n",
        "        return Mtype\n",
        "    Mtype = FindMtype(classifier)\n",
        "  \n",
        "\n",
        "    final_data=MLClassifierDFPrep(df,input_columns,dependent_var,treat_outliers=treat_outliers,treat_neg_values=treat_neg_values)\n",
        "    class_count = df.select(countDistinct(dependent_var)).collect()\n",
        "    classes = class_count[0][0]\n",
        "    classes\n",
        "\n",
        "    train,test = final_data.randomSplit([trainsplite,testsplite],seed)\n",
        "    features = final_data.select(['features']).collect()\n",
        "    \n",
        "    #set up your results table\n",
        "    columns = ['Classifier', 'Result']\n",
        "    vals = [(\"Place Holder\",\"N/A\")]\n",
        "    results = spark.createDataFrame(vals, columns)\n",
        "\n",
        "    if Mtype==\"GBTClassifier\":\n",
        "        new_result = GBTClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"RandomForestClassifier\":\n",
        "        new_result = RandomForestClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"OneVsRest\":\n",
        "        new_result = OneVsRestmodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"LogisticRegression\":\n",
        "        new_result = LogisticRegressionmodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"NaiveBayes\":\n",
        "        new_result = NaiveBayesmodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"DecisionTreeClassifier\":\n",
        "        new_result = DecisionTreeClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"LinearSVC\":\n",
        "        new_result = LinearSVCmodel(features,classes,folds,train,test,input_columns)\n",
        "    elif Mtype==\"MultilayerPerceptronClassifier\":\n",
        "      new_result = MultilayerPerceptronClassifiermodel(features,classes,folds,train,test,input_columns) \n",
        "    \n",
        "    results = results.union(new_result)\n",
        "    results = results.where(\"Classifier!='Place Holder'\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=[GBTClassifier(),RandomForestClassifier(),OneVsRest(),\n",
        "            LogisticRegression(),NaiveBayes(),DecisionTreeClassifier()\n",
        "            ,LinearSVC(),MultilayerPerceptronClassifier()]"
      ],
      "metadata": {
        "id": "z5nvA8Vvzb4k"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modeltest(df,GBTClassifier(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0iCqyqpfEYx",
        "outputId": "82049dcf-963b-4cbc-cf1c-785316d9eb9f"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            " \n",
            "\u001b[1mGBTClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+-------------------+\n",
            "|feature                 |score              |\n",
            "+------------------------+-------------------+\n",
            "|Glucose                 |0.2445106011892125 |\n",
            "|BMI                     |0.15673488723653634|\n",
            "|Age                     |0.1366733375833831 |\n",
            "|DiabetesPedigreeFunction|0.11961241647189638|\n",
            "|Insulin                 |0.11585728137788436|\n",
            "|BloodPressure           |0.09374326190721782|\n",
            "|Pregnancies             |0.08757001156117522|\n",
            "|SkinThickness           |0.04529820267269435|\n",
            "+------------------------+-------------------+\n",
            "\n",
            "None\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+-------------+------+\n",
            "|   Classifier|Result|\n",
            "+-------------+------+\n",
            "|GBTClassifier| 71.18|\n",
            "+-------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modeltest(df,RandomForestClassifier(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLo4yYCcz5hn",
        "outputId": "f7fe01e4-d1f6-4dc6-96f6-d5ce753a5d87"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            " \n",
            "\u001b[1mRandomForestClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.4347364963694499  |\n",
            "|BMI                     |0.15543666499874026 |\n",
            "|Age                     |0.14739573021724706 |\n",
            "|Insulin                 |0.06807217806009147 |\n",
            "|DiabetesPedigreeFunction|0.065477612609084   |\n",
            "|Pregnancies             |0.058389841966355535|\n",
            "|SkinThickness           |0.046688798483522115|\n",
            "|BloodPressure           |0.02380267729550975 |\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+--------------------+------+\n",
            "|          Classifier|Result|\n",
            "+--------------------+------+\n",
            "|RandomForestClass...| 72.45|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modeltest(df,OneVsRest(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVwHbthV1PGr",
        "outputId": "ba69b1fe-265c-4ce1-d07f-4e1e5ca1b216"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            " \n",
            "\u001b[1mOneVsRest\u001b[0m\n",
            "\u001b[1mIntercept: \u001b[0m 5.66188337049584 \u001b[1m\n",
            "Coefficients:\u001b[0m [-2.4044265416180717,-5.2098568611396,0.7017253197643596,-0.18688371376648574,-0.1048554518342095,-3.773771799413517,-2.2191032882175987,-0.6704600044066444]\n",
            "\u001b[1mIntercept: \u001b[0m -5.661883370495838 \u001b[1m\n",
            "Coefficients:\u001b[0m [2.404426541618076,5.209856861139596,-0.7017253197643795,0.18688371376651206,0.10485545183422967,3.7737717994135007,2.2191032882175965,0.6704600044066383]\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+----------+------+\n",
            "|Classifier|Result|\n",
            "+----------+------+\n",
            "| OneVsRest| 77.11|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modeltest(df,NaiveBayes(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu4ks4NP1Rnq",
        "outputId": "a56296c3-2040-4a84-d471-cf57e4c7bb4d"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+----------+------+\n",
            "|Classifier|Result|\n",
            "+----------+------+\n",
            "|NaiveBayes| 63.55|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modeltest(df,DecisionTreeClassifier(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqg--bep1gfG",
        "outputId": "b5452a1b-a636-4014-9178-47898cb41f4d"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.524669329184939   |\n",
            "|BMI                     |0.14609141431697234 |\n",
            "|Age                     |0.14119653880703806 |\n",
            "|Pregnancies             |0.11022998666381316 |\n",
            "|DiabetesPedigreeFunction|0.03547155437607893 |\n",
            "|SkinThickness           |0.02007767372060785 |\n",
            "|Insulin                 |0.013402060516825572|\n",
            "|BloodPressure           |0.008861442413725064|\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+--------------------+------+\n",
            "|          Classifier|Result|\n",
            "+--------------------+------+\n",
            "|DecisionTreeClass...| 71.61|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modeltest(df,LinearSVC(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jxnEq3m1keH",
        "outputId": "e67b3404-fbe5-422d-8e59-cc3cdecd5cc4"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            " \n",
            "\u001b[1mLinearSVC\u001b[0m\n",
            "Intercept: -4.217133136821038\n",
            "\u001b[1mTop 20 Coefficients\u001b[0m\n",
            "You should compares these relative to eachother\n",
            "+------------------------+-------------------+\n",
            "|feature                 |coeff              |\n",
            "+------------------------+-------------------+\n",
            "|Glucose                 |4.419698105145853  |\n",
            "|BMI                     |2.7378577519646683 |\n",
            "|DiabetesPedigreeFunction|1.8041378426905303 |\n",
            "|Pregnancies             |1.58500569398122   |\n",
            "|Age                     |0.20182264687068815|\n",
            "|Insulin                 |0.02631035060010266|\n",
            "|SkinThickness           |-0.4220906351178238|\n",
            "|BloodPressure           |-0.5103411876194818|\n",
            "+------------------------+-------------------+\n",
            "\n",
            "None\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+----------+------+\n",
            "|Classifier|Result|\n",
            "+----------+------+\n",
            "| LinearSVC| 76.69|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modeltest(df,MultilayerPerceptronClassifier(),\"Outcome\",df.columns[0:-1],0.7,0.3,123,5,True,True).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26OBDA8i1n7A",
        "outputId": "b71d967e-7979-48c9-9a24-8795f29ce05f"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+--------------------+------+\n",
            "|          Classifier|Result|\n",
            "+--------------------+------+\n",
            "|MultilayerPercept...| 72.88|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test with feature selection"
      ],
      "metadata": {
        "id": "G4mWdIfC-qim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  FeatureSelectionrandommodel(dataframe,classifier,input_columns:list,dependent_var:str,trainsplite:int,testsplite:int,seed:int,folds:int,start:int,step:int):  \n",
        "    \"\"\" return all model accuracy  with feature selection\n",
        "             \n",
        "        Parameters:\n",
        "        -------------- \n",
        "                   \n",
        "            dataframe(:class:`DataFrame) : dataframe        \n",
        "            \n",
        "            classifier : name of model incude () \n",
        "\n",
        "            dependent_var(str) : estimate the skill of the model on new data \n",
        "\n",
        "            input_columns(list) : input_columns\n",
        "            \n",
        "            trainsplite(int) :   number train splite\n",
        "\n",
        "            testsplite(int) :   number test splite\n",
        "\n",
        "            seed(int) : seed of train and test\n",
        "            \n",
        "            folds(int) : estimate the skill of the model on new data\n",
        "            \n",
        "            treat_outliers(bool) : fix outliers \n",
        "\n",
        "            treat_neg_values(bool) :fix negative value \n",
        "                       \n",
        "        Returns:\n",
        "        --------------\n",
        "            result (:class:`DataFrame) : return all  accuracy\n",
        "              \n",
        "            \"\"\"\n",
        "\n",
        "    from pyspark.ml.feature import VectorSlicer\n",
        "    from pyspark.ml.feature import ChiSqSelector\n",
        "    from pyspark.sql.functions import countDistinct\n",
        "    from pyspark.ml.linalg import Vectors\n",
        "    import numpy as np\n",
        "    def FindMtype(classifier):\n",
        "          # Intstantiate Model\n",
        "          M = classifier\n",
        "          # Learn what it is\n",
        "          Mtype = type(M).__name__\n",
        "\n",
        "          return Mtype\n",
        "    Mtype = FindMtype(classifier)\n",
        "    test2_data=MLClassifierDFPrep(df,input_columns,dependent_var,treat_outliers=True,treat_neg_values=True)\n",
        "    class_count = df.select(countDistinct(dependent_var)).collect()\n",
        "    classes = class_count[0][0]\n",
        "    classes\n",
        "    #Select the top n features and view results\n",
        "    maximum = len(input_columns)\n",
        "    for n in np.arange(2,maximum).tolist():\n",
        "        print(\"Testing top n = \",n,\" features\")\n",
        "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
        "            # For Tree classifiers\n",
        "            best_n_features = RF_featureimportances.argsort()[-n:][::-1]\n",
        "            best_n_features= best_n_features.tolist() # convert to a list\n",
        "            vs = VectorSlicer(inputCol=\"features\", outputCol=\"best_features\", indices=best_n_features)\n",
        "            bestFeaturesDf = vs.transform(test2_data)\n",
        "\n",
        "        else:\n",
        "            selector = ChiSqSelector(numTopFeatures=n, featuresCol=\"features\",\n",
        "                                outputCol=\"selectedFeatures\", labelCol=\"label\")\n",
        "            bestFeaturesDf = selector.fit(test2_data).transform(test2_data)\n",
        "            bestFeaturesDf = bestFeaturesDf.select(\"label\",\"selectedFeatures\")\n",
        "            bestFeaturesDf = bestFeaturesDf.withColumnRenamed(\"selectedFeatures\",\"features\")\n",
        "\n",
        "        # Collect features\n",
        "        features = bestFeaturesDf.select(['features']).collect()\n",
        "\n",
        "        # Split\n",
        "        train,test = bestFeaturesDf.randomSplit([0.7,0.3])\n",
        "\n",
        "        # Specify folds\n",
        "\n",
        "\n",
        "        #set up your results table\n",
        "        columns = ['Classifier', 'Result']\n",
        "        vals = [(\"Place Holder\",\"N/A\")]\n",
        "        results = spark.createDataFrame(vals, columns)\n",
        "\n",
        "        \n",
        "        if Mtype==\"GBTClassifier\":\n",
        "            new_result = GBTClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"RandomForestClassifier\":\n",
        "            new_result = RandomForestClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"OneVsRest\":\n",
        "            new_result = OneVsRestmodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"LogisticRegression\":\n",
        "            new_result = LogisticRegressionmodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"NaiveBayes\":\n",
        "            new_result = NaiveBayesmodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"DecisionTreeClassifier\":\n",
        "            new_result = DecisionTreeClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"LinearSVC\":\n",
        "            new_result = LinearSVCmodel(features,classes,folds,train,test,input_columns)\n",
        "        elif Mtype==\"MultilayerPerceptronClassifier\":\n",
        "            new_result = MultilayerPerceptronClassifiermodel(features,classes,folds,train,test,input_columns)\n",
        "        results = results.union(new_result)\n",
        "        results = results.where(\"Classifier!='Place Holder'\")\n",
        "        results.show(100,False)"
      ],
      "metadata": {
        "id": "LuXNszK67DiE"
      },
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FeatureSelectionrandommodel(df,DecisionTreeClassifier(),df.columns[0:-1],\"Outcome\",0.7,0.3,123,5,1,2)"
      ],
      "metadata": {
        "id": "IxLGIPTMCjsT",
        "outputId": "74fc4da5-1387-4fd2-e2ef-b68a3b201911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are correcting for non normality now!\n",
            "Insulin has been treated for positive (right) skewness. (skew =) 3.3734139434873414 )\n",
            "DiabetesPedigreeFunction has been treated for positive (right) skewness. (skew =) 1.9161592037386226 )\n",
            "Age has been treated for positive (right) skewness. (skew =) 1.127389259531697 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            "Testing top n =  2  features\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.5348526634496975  |\n",
            "|BMI                     |0.21481439722403298 |\n",
            "|Age                     |0.09713117413827096 |\n",
            "|Insulin                 |0.06960094286518759 |\n",
            "|DiabetesPedigreeFunction|0.04376108432647735 |\n",
            "|Pregnancies             |0.027061898795017043|\n",
            "|SkinThickness           |0.012777839201316695|\n",
            "|BloodPressure           |0.0                 |\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "+----------------------+------+\n",
            "|Classifier            |Result|\n",
            "+----------------------+------+\n",
            "|DecisionTreeClassifier|73.30 |\n",
            "+----------------------+------+\n",
            "\n",
            "Testing top n =  3  features\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.5262300750378472  |\n",
            "|Pregnancies             |0.1336669215380438  |\n",
            "|Age                     |0.11576627360594251 |\n",
            "|BMI                     |0.1027459237039147  |\n",
            "|DiabetesPedigreeFunction|0.042501130029823905|\n",
            "|BloodPressure           |0.04049669775462564 |\n",
            "|Insulin                 |0.03859297832980235 |\n",
            "|SkinThickness           |0.0                 |\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "+----------------------+------+\n",
            "|Classifier            |Result|\n",
            "+----------------------+------+\n",
            "|DecisionTreeClassifier|71.36 |\n",
            "+----------------------+------+\n",
            "\n",
            "Testing top n =  4  features\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.5396741811494522  |\n",
            "|BMI                     |0.16215762704591982 |\n",
            "|Age                     |0.13425186727539276 |\n",
            "|DiabetesPedigreeFunction|0.06474186698424578 |\n",
            "|Insulin                 |0.04315969579081614 |\n",
            "|BloodPressure           |0.030956502108313216|\n",
            "|Pregnancies             |0.025058259645860212|\n",
            "|SkinThickness           |0.0                 |\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "+----------------------+------+\n",
            "|Classifier            |Result|\n",
            "+----------------------+------+\n",
            "|DecisionTreeClassifier|70.68 |\n",
            "+----------------------+------+\n",
            "\n",
            "Testing top n =  5  features\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+-------------------+\n",
            "|feature                 |score              |\n",
            "+------------------------+-------------------+\n",
            "|Glucose                 |0.4698163901423722 |\n",
            "|BMI                     |0.19629111475301098|\n",
            "|Insulin                 |0.1076483118844517 |\n",
            "|Age                     |0.10040190773268289|\n",
            "|BloodPressure           |0.04390057656846047|\n",
            "|DiabetesPedigreeFunction|0.04152255090084259|\n",
            "|Pregnancies             |0.04041914801817923|\n",
            "|SkinThickness           |0.0                |\n",
            "+------------------------+-------------------+\n",
            "\n",
            "None\n",
            "+----------------------+------+\n",
            "|Classifier            |Result|\n",
            "+----------------------+------+\n",
            "|DecisionTreeClassifier|72.96 |\n",
            "+----------------------+------+\n",
            "\n",
            "Testing top n =  6  features\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.505798360672061   |\n",
            "|BMI                     |0.20373778010896862 |\n",
            "|Age                     |0.18165943442015048 |\n",
            "|DiabetesPedigreeFunction|0.05546892442876416 |\n",
            "|Insulin                 |0.025364365843827258|\n",
            "|Pregnancies             |0.014632976625595331|\n",
            "|SkinThickness           |0.0133381579006333  |\n",
            "|BloodPressure           |0.0                 |\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "+----------------------+------+\n",
            "|Classifier            |Result|\n",
            "+----------------------+------+\n",
            "|DecisionTreeClassifier|73.77 |\n",
            "+----------------------+------+\n",
            "\n",
            "Testing top n =  7  features\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+------------------------+--------------------+\n",
            "|feature                 |score               |\n",
            "+------------------------+--------------------+\n",
            "|Glucose                 |0.48144833391910474 |\n",
            "|BMI                     |0.18395866940358674 |\n",
            "|Age                     |0.13710137133441935 |\n",
            "|Pregnancies             |0.07730657970666463 |\n",
            "|DiabetesPedigreeFunction|0.058362604673392125|\n",
            "|SkinThickness           |0.026188663446486047|\n",
            "|Insulin                 |0.025412150369725234|\n",
            "|BloodPressure           |0.010221627146621006|\n",
            "+------------------------+--------------------+\n",
            "\n",
            "None\n",
            "+----------------------+------+\n",
            "|Classifier            |Result|\n",
            "+----------------------+------+\n",
            "|DecisionTreeClassifier|78.8  |\n",
            "+----------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Nx1Z8pYvCvC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}